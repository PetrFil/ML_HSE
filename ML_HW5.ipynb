{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_HW5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk36ZG-qauVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_jVl-RzaoYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.metrics import *\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression, LinearRegression, LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier,  BaggingClassifier, BaggingRegressor, RandomTreesEmbedding,GradientBoostingClassifier\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from nltk import word_tokenize\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import re\n",
        "import nltk\n",
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "sno = nltk.stem.SnowballStemmer('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApI2dTxhYlfK",
        "colab_type": "code",
        "outputId": "02375f31-08d4-4c0d-8574-c57cbec40df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data_url = 'https://raw.githubusercontent.com/TatianaShavrina/hse_ml_m1/master/ensembles/complaints.csv'\n",
        "data = pd.read_csv(data_url, sep='\\t')\n",
        "data.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COMPLAINT_ID</th>\n",
              "      <th>DATE</th>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <th>ISSUE_ID</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3178905</td>\n",
              "      <td>03/13/2019</td>\n",
              "      <td>44</td>\n",
              "      <td>318</td>\n",
              "      <td>go year . contact advis never took loan . advi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3175952</td>\n",
              "      <td>03/12/2019</td>\n",
              "      <td>44</td>\n",
              "      <td>349</td>\n",
              "      <td>mail valid debt xx/xx/19 valid receiv , receiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3174747</td>\n",
              "      <td>03/09/2019</td>\n",
              "      <td>44</td>\n",
              "      <td>16</td>\n",
              "      <td>xx/xx/xxxx appli receiv onlin loan bluechip fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3173291</td>\n",
              "      <td>03/08/2019</td>\n",
              "      <td>44</td>\n",
              "      <td>16</td>\n",
              "      <td>xx/xx/xxxx appli receiv onlin loan . loan amou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3172221</td>\n",
              "      <td>03/07/2019</td>\n",
              "      <td>44</td>\n",
              "      <td>48</td>\n",
              "      <td>told husband left bill . debt would pay within...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   COMPLAINT_ID  ...                                       cleaned_text\n",
              "0       3178905  ...  go year . contact advis never took loan . advi...\n",
              "1       3175952  ...  mail valid debt xx/xx/19 valid receiv , receiv...\n",
              "2       3174747  ...  xx/xx/xxxx appli receiv onlin loan bluechip fi...\n",
              "3       3173291  ...  xx/xx/xxxx appli receiv onlin loan . loan amou...\n",
              "4       3172221  ...  told husband left bill . debt would pay within...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqV1GMxkwY0g",
        "colab_type": "text"
      },
      "source": [
        "Попробуйте поднять качество классификации до 70% с помощью известных вам методов препроцессинга и Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3nCYDPX2LPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words =  set(stopwords.words('english')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4qpBXh8rf7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stem_tokenizer(text):\n",
        "    return [sno.stem(t) for t in word_tokenize(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGeAnV3ntuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(line): #удаляем стоп-слова\n",
        "  line_token = stem_tokenizer(line)\n",
        "  filtered_line = [w for w in line_token if not w in stop_words]\n",
        "  filtered_line = ' '.join(filtered_line)\n",
        "  return filtered_line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9cxekroq9pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"preprocessed_text\"] = data[\"cleaned_text\"].apply(preprocessing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-QsSdB31BMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data[\"PRODUCT_ID\"]\n",
        "X = data[\"preprocessed_text\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNEeoV2nTTtA",
        "colab_type": "code",
        "outputId": "9f59a0ab-b08e-459f-aeff-7248b7ad8ca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model = gensim.models.Word2Vec(X_train, size=100)\n",
        "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThHQ3E92pVzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        self.dim = 100\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQj7mQSF1vCS",
        "colab_type": "code",
        "outputId": "4fc1d821-2ba0-4c00-b953-ee96a7a32144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "clf1 = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42)\n",
        "clf2 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "eclf = VotingClassifier(estimators=[\n",
        "        ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
        "\n",
        "voting = Pipeline([\n",
        "    ('feats', FeatureUnion([\n",
        "        ('tfidf', TfidfVectorizer(tokenizer=stem_tokenizer)),\n",
        "        (\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v))])),\n",
        "    ('clf', SVC(class_weight=\"balanced\", random_state =42))\n",
        "    ])\n",
        "\n",
        "voting = voting.fit(X_train, y_train)\n",
        "predictions = voting.predict(X_test)\n",
        "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.71\n",
            "Recall:   0.71\n",
            "F1-measure:   0.71\n",
            "Accuracy:   0.71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg91VQenYhKa",
        "colab_type": "text"
      },
      "source": [
        "Основываясь на своих знаниях об ансамблировании различных моделей, на данных из complaints.csv достигните наилучшего результата"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUJLGnnLw6ji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_url = 'https://raw.githubusercontent.com/TatianaShavrina/hse_ml_m1/master/ensembles/complaints.csv'\n",
        "data = pd.read_csv(data_url, sep='\\t')\n",
        "data.head()\n",
        "y = data[\"PRODUCT_ID\"]\n",
        "X = data[\"cleaned_text\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDySnDoj7lxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer(tokenizer=stem_tokenizer, max_features=800, min_df=0.001, max_df=0.6)\n",
        "X = cv.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FRGuwOq-Fqq",
        "colab_type": "text"
      },
      "source": [
        "##Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUcP1hu42vU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = GradientBoostingClassifier(n_estimators=150,  random_state=42)\n",
        "clf2 = RandomForestClassifier(n_estimators=150, random_state=42)\n",
        "clf3 = ExtraTreesClassifier(n_estimators=150, random_state=42)\n",
        "\n",
        "bagging1 = BaggingClassifier(base_estimator=clf1, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
        "bagging2 = BaggingClassifier(base_estimator=clf2, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
        "bagging3 = BaggingClassifier(base_estimator=clf2, n_estimators=10, max_samples=0.8, max_features=0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsIqof7u3NTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "89ef25fb-1b2a-4d07-c4e9-80598a859374"
      },
      "source": [
        "label = ['Gradient Boosting', 'RandomForestClassifier', 'ExtraTreesClassifier', 'Bagging Gradient Boosting', 'Bagging Random Forest Classifier', 'Bagging Extra Trees Classifier']\n",
        "clf_list = [clf1, clf2, clf3, clf4, clf5, bagging1, bagging2, bagging3, bagging4, bagging5]\n",
        "for clf, label in zip(clf_list, label):        \n",
        "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
        "    print (\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.63 (+/- 0.01) [Gradient Boosting]\n",
            "Accuracy: 0.63 (+/- 0.01) [RandomForestClassifier]\n",
            "Accuracy: 0.62 (+/- 0.01) [ExtraTreesClassifier]\n",
            "Accuracy: 0.63 (+/- 0.01) [Bagging Gradient Boosting]\n",
            "Accuracy: 0.62 (+/- 0.01) [Bagging Random Forest Classifier]\n",
            "Accuracy: 0.64 (+/- 0.02) [Bagging Extra Trees Classifier]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZL68iKgF53f",
        "colab_type": "text"
      },
      "source": [
        "##Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztNPNAWRF7Ya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
        "\n",
        "num_est = [1, 2, 3, 10]\n",
        "label = ['AdaBoost (n_est=1)', 'AdaBoost (n_est=2)', 'AdaBoost (n_est=3)', 'AdaBoost (n_est=10)']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CmJ4fKvGLk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "55baee38-ce9d-404e-f415-e3bd1a24b90e"
      },
      "source": [
        "for n_est, label in zip(num_est, label):   \n",
        "  boosting = AdaBoostClassifier(base_estimator=clf, n_estimators=n_est)   \n",
        "  boosting.fit(X, y) \n",
        "  scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
        "  print (\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.63 (+/- 0.01) [AdaBoost (n_est=1)]\n",
            "Accuracy: 0.63 (+/- 0.01) [AdaBoost (n_est=2)]\n",
            "Accuracy: 0.63 (+/- 0.01) [AdaBoost (n_est=3)]\n",
            "Accuracy: 0.63 (+/- 0.01) [AdaBoost (n_est=10)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h65T6hqd-IQ3",
        "colab_type": "text"
      },
      "source": [
        "##Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzBDR3-i-i5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = GradientBoostingClassifier(n_estimators=150,  random_state=42)\n",
        "clf2 = RandomForestClassifier(n_estimators=150, random_state=42)\n",
        "clf3 = ExtraTreesClassifier(n_estimators=150, random_state=42)\n",
        "lr = LogisticRegression(max_iter=50000)\n",
        "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4], \n",
        "                          meta_classifier=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkxhKtIbAmNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = ['GradientBoosting', 'RandomForestClassifier', 'Extra Trees', 'Stacking Classifier']\n",
        "clf_list = [clf1, clf2, clf3, sclf]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGFLFabg-nOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "14e38875-7255-4e42-ead4-4446a8810a12"
      },
      "source": [
        "clf_cv_mean = []\n",
        "clf_cv_std = []\n",
        "for clf, label in zip(clf_list, label):\n",
        "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
        "    print (\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
        "    clf_cv_mean.append(scores.mean())\n",
        "    clf_cv_std.append(scores.std())"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.63 (+/- 0.01) [GradientBoosting]\n",
            "Accuracy: 0.63 (+/- 0.01) [RandomForestClassifier]\n",
            "Accuracy: 0.62 (+/- 0.01) [Extra Trees]\n",
            "Accuracy: 0.60 (+/- 0.01) [Stacking Classifier]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}