{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_EXAM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0--aU128RXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "4f4c1304-6327-4268-f34f-a5289d5faeca"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: eli5 in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.18.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.15.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QndyMKHkhm3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "37290bb3-d1ec-4d8b-9795-92b55cfac67c"
      },
      "source": [
        "import pandas as pd\n",
        "import gensim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from collections import Counter\n",
        "import gensim\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import *\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import gensim.downloader as api\n",
        "\n",
        "import re \n",
        "from string import punctuation as punct"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6QYjIqohdgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "aeea7f8d-4ca8-45d0-9646-b79e70512f2c"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9Mc0mMLi6HS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdrive = '/gdrive/My Drive/'\n",
        "path = gdrive + \"jigsaw-toxic-comment-train.csv\"\n",
        "quora = pd.read_csv(path)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbB7RiJXjKaC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "851743df-9491-4465-c5c4-738f41e98b00"
      },
      "source": [
        "quora.size"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1788392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxNxUcuhCYVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora = quora.sample(frac=0.5, random_state=42)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHsAI-Y_CdTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1a83c582-498a-4500-87e7-8c49bd549096"
      },
      "source": [
        "quora.size"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "894192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wabMj9nDyVj-",
        "colab_type": "text"
      },
      "source": [
        "##Анализ всех дополнительных колонок тональности (как проявляется тот или иной тип токсичности, как в данных это представлено, какие есть пограничные случаи) - 2.5 балла"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCnU6gyFfnyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "5247df74-ed3b-465d-b7f2-8b2b5b95e6be"
      },
      "source": [
        "quora.corr()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.287592</td>\n",
              "      <td>0.696539</td>\n",
              "      <td>0.155648</td>\n",
              "      <td>0.665785</td>\n",
              "      <td>0.273658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>severe_toxic</th>\n",
              "      <td>0.287592</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.370873</td>\n",
              "      <td>0.119363</td>\n",
              "      <td>0.341412</td>\n",
              "      <td>0.200105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>obscene</th>\n",
              "      <td>0.696539</td>\n",
              "      <td>0.370873</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.132644</td>\n",
              "      <td>0.740350</td>\n",
              "      <td>0.289751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>threat</th>\n",
              "      <td>0.155648</td>\n",
              "      <td>0.119363</td>\n",
              "      <td>0.132644</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.143322</td>\n",
              "      <td>0.094517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insult</th>\n",
              "      <td>0.665785</td>\n",
              "      <td>0.341412</td>\n",
              "      <td>0.740350</td>\n",
              "      <td>0.143322</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.339152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>identity_hate</th>\n",
              "      <td>0.273658</td>\n",
              "      <td>0.200105</td>\n",
              "      <td>0.289751</td>\n",
              "      <td>0.094517</td>\n",
              "      <td>0.339152</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  toxic  severe_toxic  ...    insult  identity_hate\n",
              "toxic          1.000000      0.287592  ...  0.665785       0.273658\n",
              "severe_toxic   0.287592      1.000000  ...  0.341412       0.200105\n",
              "obscene        0.696539      0.370873  ...  0.740350       0.289751\n",
              "threat         0.155648      0.119363  ...  0.143322       0.094517\n",
              "insult         0.665785      0.341412  ...  1.000000       0.339152\n",
              "identity_hate  0.273658      0.200105  ...  0.339152       1.000000\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZcOMYkwsZ28",
        "colab_type": "text"
      },
      "source": [
        "1) Токсичность комментариев больше всего коррелирует с обсценной лексикой и оскорблениями. Наименьшая корреляция с угрозами.\n",
        "2) У \"острой токсичности\" (severe_toxic) корреляции выглядят похоже, но с более низкими значениями. \n",
        "3) Обсценная лексика больше всего коррелирует с оскорблениями и токсичностью, в меньшей степени - с угрозами. \n",
        "4) Угрозы коррелируют со всеми показателями похожим образом незначительно (но в наибольшей степени - с токсичностью). \n",
        "5) Оскорбления коррелируют больше всего с обсценной лексикой и токсичностью, а меньше всего - с угрозами. \n",
        "6) Ненависть к социальным группам больше всего коррелирует с оскорблениями, \n",
        "обсценной лексикой и токсичностью, однако значение корреляции меньше, чем у корреляции большинства предыдущих метрик между собой."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6-O7Srpn2gQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "4e5d4df7-095b-4d19-c3dc-acfa44c750fe"
      },
      "source": [
        "quora.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>223549.000000</td>\n",
              "      <td>223549.000000</td>\n",
              "      <td>223549.000000</td>\n",
              "      <td>223549.000000</td>\n",
              "      <td>223549.000000</td>\n",
              "      <td>223549.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.095657</td>\n",
              "      <td>0.008777</td>\n",
              "      <td>0.054306</td>\n",
              "      <td>0.003082</td>\n",
              "      <td>0.050566</td>\n",
              "      <td>0.009470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.294121</td>\n",
              "      <td>0.093272</td>\n",
              "      <td>0.226621</td>\n",
              "      <td>0.055431</td>\n",
              "      <td>0.219110</td>\n",
              "      <td>0.096852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               toxic   severe_toxic  ...         insult  identity_hate\n",
              "count  223549.000000  223549.000000  ...  223549.000000  223549.000000\n",
              "mean        0.095657       0.008777  ...       0.050566       0.009470\n",
              "std         0.294121       0.093272  ...       0.219110       0.096852\n",
              "min         0.000000       0.000000  ...       0.000000       0.000000\n",
              "25%         0.000000       0.000000  ...       0.000000       0.000000\n",
              "50%         0.000000       0.000000  ...       0.000000       0.000000\n",
              "75%         0.000000       0.000000  ...       0.000000       0.000000\n",
              "max         1.000000       1.000000  ...       1.000000       1.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHlL2yejF0fg",
        "colab_type": "text"
      },
      "source": [
        "Наибольшее среднее значение у токсичных комментариев и комментариев, содержащих обсценную лексику и оскорбления. Наибольшее среднеквадратическое отклонение также у токсичности, обсценной лексики и оскорблений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku0gnsxdGjH2",
        "colab_type": "text"
      },
      "source": [
        "###Функции для подсчета статистик"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aJnXIV8Je8k",
        "colab_type": "text"
      },
      "source": [
        "Некоторые идеи(функцию raw_text) подсмотрел здесь: https://github.com/lwahomura/ML/blob/master/Exam_sharing.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hauHvt8DI72A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def raw_text(text): # without meta symbols\n",
        "  text = re.sub(\"\\n|\\t|\\s\\\"\", \" \", text)\n",
        "  return text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8aVoSlhJTaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def digits(text):\n",
        "  d = re.findall('[1-9]', text)\n",
        "  return len(d) \n",
        "\n",
        "\n",
        "def digits_ratio(text):\n",
        "  ratio = digits(text)/len(raw_text(text))\n",
        "  return ratio\n",
        "\n",
        "\n",
        "def new_lines(text):\n",
        "  all_new_lines = re.findall('\\n', text) \n",
        "  return len(all_new_lines)\n",
        "\n",
        "\n",
        "def words_numb(text):\n",
        "  tokenized = raw_text(text).split()\n",
        "  return len(tokenized)\n",
        "\n",
        "\n",
        "def words_mean_len(text):\n",
        "  tokenized = raw_text(text).split()\n",
        "  n, token_sum = 0, 0\n",
        "  for token in tokenized:\n",
        "    n+=1\n",
        "    token_sum += len(token)\n",
        "  return token_sum/n\n",
        "\n",
        "\n",
        "def punct_numb(text):\n",
        "  all_punct = [ch for ch in text if ch in punct]\n",
        "  return len(all_punct)\n",
        "\n",
        "\n",
        "def caps_numb(text):\n",
        "  all_caps = [ch for ch in text if ch.isupper()]\n",
        "  return len(all_caps)\n",
        "\n",
        "\n",
        "def caps_ratio(text):\n",
        "  ratio = caps_numb(text)/len(raw_text(text))\n",
        "  return ratio\n",
        "\n",
        "\n",
        "def no_latin(text):\n",
        "  no_latin = re.findall('[^a-zA-Z]', text)\n",
        "  return len(no_latin)\n",
        "\n",
        "\n",
        "def no_latin_ratio(text):\n",
        "  ratio = no_latin(raw_text(text))/len(raw_text(text))\n",
        "  return ratio\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slTMJ5UGP_tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora['length'] = quora.comment_text.apply(len)\n",
        "quora['digits_numb'] = quora.comment_text.apply(digits)\n",
        "quora['digits_ratio'] = quora.comment_text.apply(digits_ratio)\n",
        "quora['lines'] = quora.comment_text.apply(new_lines)\n",
        "quora['words_numb'] = quora.comment_text.apply(words_numb)\n",
        "quora['words_mean_len'] = quora.comment_text.apply(words_mean_len)\n",
        "quora['punct_numb'] = quora.comment_text.apply(punct_numb)\n",
        "quora['caps_numb'] = quora.comment_text.apply(caps_numb)\n",
        "quora['caps_ratio'] = quora.comment_text.apply(caps_ratio)\n",
        "quora['no_latin_number'] = quora.comment_text.apply(no_latin)\n",
        "quora['no_latin_ratio'] = quora.comment_text.apply(no_latin_ratio)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojCQwM_krSXO",
        "colab_type": "text"
      },
      "source": [
        "###Анализ колонок тональности по-отдельности"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pYXZM4RrwUh",
        "colab_type": "text"
      },
      "source": [
        "####toxic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEMRkJT_wUxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "370f966b-641e-43fc-9714-f764da2e36ff"
      },
      "source": [
        "quora.groupby('toxic')['length', 'digits_numb', 'digits_ratio', 'lines', 'words_numb', 'words_mean_len', \n",
        "                      'punct_numb', 'caps_numb', 'caps_ratio', 'no_latin_number', 'no_latin_ratio'].agg(['mean'])"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>digits_numb</th>\n",
              "      <th>digits_ratio</th>\n",
              "      <th>lines</th>\n",
              "      <th>words_numb</th>\n",
              "      <th>words_mean_len</th>\n",
              "      <th>punct_numb</th>\n",
              "      <th>caps_numb</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>no_latin_number</th>\n",
              "      <th>no_latin_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>403.232954</td>\n",
              "      <td>2.629527</td>\n",
              "      <td>0.008996</td>\n",
              "      <td>2.622802</td>\n",
              "      <td>68.226446</td>\n",
              "      <td>4.966202</td>\n",
              "      <td>17.017615</td>\n",
              "      <td>14.637203</td>\n",
              "      <td>0.045710</td>\n",
              "      <td>93.537604</td>\n",
              "      <td>0.241248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>281.940289</td>\n",
              "      <td>1.556899</td>\n",
              "      <td>0.008022</td>\n",
              "      <td>2.141826</td>\n",
              "      <td>48.719348</td>\n",
              "      <td>5.062140</td>\n",
              "      <td>13.837739</td>\n",
              "      <td>44.491657</td>\n",
              "      <td>0.111537</td>\n",
              "      <td>66.959130</td>\n",
              "      <td>0.246807</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           length digits_numb  ... no_latin_number no_latin_ratio\n",
              "             mean        mean  ...            mean           mean\n",
              "toxic                          ...                               \n",
              "0      403.232954    2.629527  ...       93.537604       0.241248\n",
              "1      281.940289    1.556899  ...       66.959130       0.246807\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OPS4KBLw-3m",
        "colab_type": "text"
      },
      "source": [
        "Для токсичных и нетоксичных комментариев мы можем наблюдать следующие закономерности:\n",
        "1) Токсичные комментарии в среднем значительно короче (по символам)\n",
        "2) В токсичных комментариях меньше цифр\n",
        "3) Доля цифр в токсичных комментариях также меньше\n",
        "4) В токсичных текстах меньшее число переводов строк \n",
        "5) Нетоксичные тексты многословнее\n",
        "6) Средняя длина слова сопоставима, но в токсичных комментариях все же немного больше\n",
        "7) В нетоксичных комментариях больше знаков пунктуации\n",
        "8) В ТОКСИЧНЫХ ТЕКСТАХ ЗНАЧИТЕЛЬНО БОЛЬШЕ СИМВОЛОВ В ВЕРХНЕМ РЕГИСТРЕ (в 3 раза)\n",
        "9) Доля символов в верхнем регистре соответственно тоже больше в токсичных текстах\n",
        "10) Нелатинские символы в среднем чаще встречаются в нейтральных текстах\n",
        "11) При этом доля нелатинских символов, наоборот, немного выше в токсичных текстах"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SZ3haIU0r4v0"
      },
      "source": [
        "####severe_toxic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU_696VJzQCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "8c9ea110-2565-4acd-a698-e939566b0547"
      },
      "source": [
        "quora.groupby('severe_toxic')['length', 'digits_numb', 'digits_ratio', 'lines', 'words_numb', 'words_mean_len', \n",
        "                      'punct_numb', 'caps_numb', 'caps_ratio', 'no_latin_number', 'no_latin_ratio'].agg(['mean'])"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>digits_numb</th>\n",
              "      <th>digits_ratio</th>\n",
              "      <th>lines</th>\n",
              "      <th>words_numb</th>\n",
              "      <th>words_mean_len</th>\n",
              "      <th>punct_numb</th>\n",
              "      <th>caps_numb</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>no_latin_number</th>\n",
              "      <th>no_latin_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>severe_toxic</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>390.598563</td>\n",
              "      <td>2.535815</td>\n",
              "      <td>0.008921</td>\n",
              "      <td>2.565948</td>\n",
              "      <td>66.200060</td>\n",
              "      <td>4.958836</td>\n",
              "      <td>16.589331</td>\n",
              "      <td>16.115940</td>\n",
              "      <td>0.050661</td>\n",
              "      <td>90.718538</td>\n",
              "      <td>0.241723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>512.880041</td>\n",
              "      <td>1.534643</td>\n",
              "      <td>0.006851</td>\n",
              "      <td>3.831437</td>\n",
              "      <td>85.223371</td>\n",
              "      <td>6.868614</td>\n",
              "      <td>31.013444</td>\n",
              "      <td>174.547053</td>\n",
              "      <td>0.204576</td>\n",
              "      <td>123.354705</td>\n",
              "      <td>0.248146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  length digits_numb  ... no_latin_number no_latin_ratio\n",
              "                    mean        mean  ...            mean           mean\n",
              "severe_toxic                          ...                               \n",
              "0             390.598563    2.535815  ...       90.718538       0.241723\n",
              "1             512.880041    1.534643  ...      123.354705       0.248146\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FhwfgFUL5JM1"
      },
      "source": [
        "Для очень токсичных комментариев и комментариев со значением severe_toxic=0 мы можем наблюдать следующие закономерности:\n",
        "1) Очень токсичные комментарии в среднем значительно длиннее по символам\n",
        "2) В очень токсичных комментариях меньше цифр\n",
        "3) Доля цифр в очень токсичных комментариях также меньше\n",
        "4) В очень токсичных текстах большее число переводов строк \n",
        "5) Очень токсичные тексты многословнее\n",
        "6) Средняя длина слова больше в очень токсичных комментариях\n",
        "7) В очень токсичных комментариях больше знаков пунктуации\n",
        "8) В очень токсичных комментариях в 10 раз больше букв в верхнем регистре\n",
        "9) Доля символов в верхнем регистре соответственно тоже больше в очень токсичных текстах (в 4 раза)\n",
        "10) Нелатинские символы в среднем чаще встречаются в очень токсичных текстах\n",
        "11) При этом доля нелатинских символов сопоставими, но немного больше в очень токсичных текстах"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vkHBCefdr5FG"
      },
      "source": [
        "####obscene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vM1NhJvFxAb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "3215fd37-6440-4531-d7f6-072deea32294"
      },
      "source": [
        "quora.groupby('obscene')['length', 'digits_numb', 'digits_ratio', 'lines', 'words_numb', 'words_mean_len', \n",
        "                      'punct_numb', 'caps_numb', 'caps_ratio', 'no_latin_number', 'no_latin_ratio'].agg(['mean'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>digits_numb</th>\n",
              "      <th>digits_ratio</th>\n",
              "      <th>lines</th>\n",
              "      <th>words_numb</th>\n",
              "      <th>words_mean_len</th>\n",
              "      <th>punct_numb</th>\n",
              "      <th>caps_numb</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>no_latin_number</th>\n",
              "      <th>no_latin_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>obscene</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>397.609200</td>\n",
              "      <td>2.566141</td>\n",
              "      <td>0.008927</td>\n",
              "      <td>2.592839</td>\n",
              "      <td>67.342614</td>\n",
              "      <td>4.953150</td>\n",
              "      <td>16.838666</td>\n",
              "      <td>15.376557</td>\n",
              "      <td>0.047871</td>\n",
              "      <td>92.280479</td>\n",
              "      <td>0.241347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>287.395395</td>\n",
              "      <td>1.844294</td>\n",
              "      <td>0.008484</td>\n",
              "      <td>2.297664</td>\n",
              "      <td>49.235547</td>\n",
              "      <td>5.364332</td>\n",
              "      <td>14.532715</td>\n",
              "      <td>54.443432</td>\n",
              "      <td>0.124190</td>\n",
              "      <td>68.589034</td>\n",
              "      <td>0.249340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             length digits_numb  ... no_latin_number no_latin_ratio\n",
              "               mean        mean  ...            mean           mean\n",
              "obscene                          ...                               \n",
              "0        397.609200    2.566141  ...       92.280479       0.241347\n",
              "1        287.395395    1.844294  ...       68.589034       0.249340\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tD7fUFtH5KiD"
      },
      "source": [
        "Для комментариев с обсценной лексикой и без(обычных) мы можем наблюдать следующие закономерности:\n",
        "1) Обычные комментарии в среднем значительно длиннее по символам\n",
        "2) В обычных комментариях больше цифр\n",
        "3) Доля цифр в обычных комментариях также немного больше\n",
        "4) В обычных текстах большее число переводов строк \n",
        "5) Тексты без обсценной лексики многословнее\n",
        "6) Средняя длина слова больше в комментариях с обсценной лексикой\n",
        "7) Пунктуации больще в обычных комментариях\n",
        "8) Букв в верхнем регистре больше в комментариях с обсценной лексикой\n",
        "9) Доля таких букв тоже больше в комментариях с обсценной лексикой\n",
        "10) Нелатинские символы в среднем чаще встречаются в текстах без обсценной лексики\n",
        "11) При этом доля нелатинских символов выше в текстах с обсценной лексикой"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aoOSS4_Or5Pe"
      },
      "source": [
        "####threat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5xeD4rOzxAy7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "760979e2-0315-44d3-c8ab-cb750b5069f9"
      },
      "source": [
        "quora.groupby('threat')['length', 'digits_numb', 'digits_ratio', 'lines', 'words_numb', 'words_mean_len', \n",
        "                      'punct_numb', 'caps_numb', 'caps_ratio', 'no_latin_number', 'no_latin_ratio'].agg(['mean'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>digits_numb</th>\n",
              "      <th>digits_ratio</th>\n",
              "      <th>lines</th>\n",
              "      <th>words_numb</th>\n",
              "      <th>words_mean_len</th>\n",
              "      <th>punct_numb</th>\n",
              "      <th>caps_numb</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>no_latin_number</th>\n",
              "      <th>no_latin_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>threat</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>391.832811</td>\n",
              "      <td>2.532563</td>\n",
              "      <td>0.008915</td>\n",
              "      <td>2.577458</td>\n",
              "      <td>66.385247</td>\n",
              "      <td>4.975970</td>\n",
              "      <td>16.713236</td>\n",
              "      <td>17.270552</td>\n",
              "      <td>0.051695</td>\n",
              "      <td>91.030917</td>\n",
              "      <td>0.241753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>328.859425</td>\n",
              "      <td>0.600639</td>\n",
              "      <td>0.004625</td>\n",
              "      <td>2.376997</td>\n",
              "      <td>59.025559</td>\n",
              "      <td>4.757471</td>\n",
              "      <td>17.028754</td>\n",
              "      <td>94.418530</td>\n",
              "      <td>0.158096</td>\n",
              "      <td>80.306709</td>\n",
              "      <td>0.251051</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            length digits_numb  ... no_latin_number no_latin_ratio\n",
              "              mean        mean  ...            mean           mean\n",
              "threat                          ...                               \n",
              "0       391.832811    2.532563  ...       91.030917       0.241753\n",
              "1       328.859425    0.600639  ...       80.306709       0.251051\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QKF0tpvd5LXt"
      },
      "source": [
        "Для комментариев с угрозами и без(обычных) мы можем наблюдать следующие закономерности:\n",
        "1) Длина текстов ближе, чем в других парах. Комментарии с угрозами все равно длиннее.\n",
        "2) В обычных комментариях больше цифр\n",
        "3) Доля цифр в обычных комментариях также немного больше\n",
        "4) В обычных текстах большее число переводов строк \n",
        "5) Тексты без угроз многословнее\n",
        "6) Средняя длина слов сопоставима, но больше в текстах без угроз\n",
        "7) Пунктуации почти одинаковая, немного больше ее в текстах с угрозами\n",
        "8) Букв в верхнем регистре больше в комментариях с угрозами(в несколько раз)\n",
        "9) Доля таких букв тоже больше в комментариях с угрозами\n",
        "10) Нелатинские символы в среднем чаще встречаются в текстах без угроз\n",
        "11) При этом доля нелатинских символов выше в текстах с угрозами"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQorSOaSry9S",
        "colab_type": "text"
      },
      "source": [
        "####insult \t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AJHLZ75rxB48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "e2f7613e-e6ea-4417-cf35-87c864433819"
      },
      "source": [
        "quora.groupby('insult')['length', 'digits_numb', 'digits_ratio', 'lines', 'words_numb', 'words_mean_len', \n",
        "                      'punct_numb', 'caps_numb', 'caps_ratio', 'no_latin_number', 'no_latin_ratio'].agg(['mean'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>digits_numb</th>\n",
              "      <th>digits_ratio</th>\n",
              "      <th>lines</th>\n",
              "      <th>words_numb</th>\n",
              "      <th>words_mean_len</th>\n",
              "      <th>punct_numb</th>\n",
              "      <th>caps_numb</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>no_latin_number</th>\n",
              "      <th>no_latin_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insult</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>397.738428</td>\n",
              "      <td>2.565777</td>\n",
              "      <td>0.008963</td>\n",
              "      <td>2.600317</td>\n",
              "      <td>67.355826</td>\n",
              "      <td>4.954506</td>\n",
              "      <td>16.854483</td>\n",
              "      <td>15.764177</td>\n",
              "      <td>0.048343</td>\n",
              "      <td>92.314748</td>\n",
              "      <td>0.241566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>277.098669</td>\n",
              "      <td>1.799645</td>\n",
              "      <td>0.007762</td>\n",
              "      <td>2.135759</td>\n",
              "      <td>47.694942</td>\n",
              "      <td>5.368130</td>\n",
              "      <td>14.070275</td>\n",
              "      <td>49.929370</td>\n",
              "      <td>0.120739</td>\n",
              "      <td>66.253416</td>\n",
              "      <td>0.245784</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            length digits_numb  ... no_latin_number no_latin_ratio\n",
              "              mean        mean  ...            mean           mean\n",
              "insult                          ...                               \n",
              "0       397.738428    2.565777  ...       92.314748       0.241566\n",
              "1       277.098669    1.799645  ...       66.253416       0.245784\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v3d47K1s5MD1"
      },
      "source": [
        "Для комментариев с оскорблениями и без(обычных) мы можем наблюдать следующие закономерности:\n",
        "1) Посимвольная длина больше в текстах без оскорблений\n",
        "2) В обычных комментариях больше цифр\n",
        "3) Доля цифр в обычных комментариях также немного больше\n",
        "4) В обычных текстах большее число переводов строк \n",
        "5) Тексты без оскорблений многословнее\n",
        "6) Средняя длина слов сопоставима, но больше в текстах с оскорблениями\n",
        "7) Больше пунктуации в текстах без оскорблений\n",
        "8) Букв в верхнем регистре больше в комментариях с оскорблениями(в несколько раз)\n",
        "9) Доля таких букв тоже больше в комментариях с оскорблениями\n",
        "10) Нелатинские символы в среднем чаще встречаются в текстах без оскорблений\n",
        "11) При этом доля нелатинских символов похожа, немного выше она в текстах с оскорблениями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7gfEpF3SsGmK"
      },
      "source": [
        "####identity_hate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CNoTX588xCQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "6d42b094-2944-4edf-a9ea-c529778d4790"
      },
      "source": [
        "quora.groupby('identity_hate')['length', 'digits_numb', 'digits_ratio', 'lines', 'words_numb', 'words_mean_len', \n",
        "                      'punct_numb', 'caps_numb', 'caps_ratio', 'no_latin_number', 'no_latin_ratio'].agg(['mean'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>digits_numb</th>\n",
              "      <th>digits_ratio</th>\n",
              "      <th>lines</th>\n",
              "      <th>words_numb</th>\n",
              "      <th>words_mean_len</th>\n",
              "      <th>punct_numb</th>\n",
              "      <th>caps_numb</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>no_latin_number</th>\n",
              "      <th>no_latin_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>identity_hate</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>392.386404</td>\n",
              "      <td>2.531178</td>\n",
              "      <td>0.008921</td>\n",
              "      <td>2.575999</td>\n",
              "      <td>66.505508</td>\n",
              "      <td>4.957957</td>\n",
              "      <td>16.761855</td>\n",
              "      <td>16.985689</td>\n",
              "      <td>0.051121</td>\n",
              "      <td>91.217423</td>\n",
              "      <td>0.241801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>312.554795</td>\n",
              "      <td>2.090998</td>\n",
              "      <td>0.006898</td>\n",
              "      <td>2.674168</td>\n",
              "      <td>51.098826</td>\n",
              "      <td>6.861070</td>\n",
              "      <td>11.541096</td>\n",
              "      <td>71.768102</td>\n",
              "      <td>0.146475</td>\n",
              "      <td>67.535225</td>\n",
              "      <td>0.239336</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   length digits_numb  ... no_latin_number no_latin_ratio\n",
              "                     mean        mean  ...            mean           mean\n",
              "identity_hate                          ...                               \n",
              "0              392.386404    2.531178  ...       91.217423       0.241801\n",
              "1              312.554795    2.090998  ...       67.535225       0.239336\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L7Br2ycA5NHC"
      },
      "source": [
        "Для комментариев с ненавистью к соц. группам и без(обычных) мы можем наблюдать следующие закономерности:\n",
        "1) Посимвольная длина больше в обычных текстах \n",
        "2) В обычных комментариях больше цифр\n",
        "3) Доля цифр в обычных комментариях также немного больше\n",
        "4) В обычных текстах меньшее число переводов строк \n",
        "5) Тексты без ненависти к соц. группам многословнее\n",
        "6) Средняя длина слов больше в текстах с враждой к соц. группам\n",
        "7) Больше пунктуации в обычных текстах \n",
        "8) Букв в верхнем регистре больше в комментариях с враждой к соц. группам\n",
        "9) Доля таких букв тоже больше в комментариях с ненавистью к соц. группам\n",
        "10) Нелатинские символы в среднем чаще встречаются в обычных текстах\n",
        "11) При этом доля нелатинских символов похожа, немного выше она в обычных комментариях"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H6kabENxVlD",
        "colab_type": "text"
      },
      "source": [
        "###Пары целевой переменной (toxic) с другими колонками тональности"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI5CJU3UTroW",
        "colab_type": "text"
      },
      "source": [
        "####Toxic-severe_toxic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV3JGhqt_J0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "683901b4-4927-4200-9423-c3ae8d1e8233"
      },
      "source": [
        "quora.groupby(['toxic', 'severe_toxic'])['length', 'digits_numb', 'digits_ratio', 'lines', 'words_numb', 'words_mean_len', \n",
        "                      'punct_numb', 'caps_numb', 'caps_ratio', 'no_latin_number', 'no_latin_ratio'].agg(['mean'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>digits_numb</th>\n",
              "      <th>digits_ratio</th>\n",
              "      <th>lines</th>\n",
              "      <th>words_numb</th>\n",
              "      <th>words_mean_len</th>\n",
              "      <th>punct_numb</th>\n",
              "      <th>caps_numb</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>no_latin_number</th>\n",
              "      <th>no_latin_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <td>403.232954</td>\n",
              "      <td>2.629527</td>\n",
              "      <td>0.008996</td>\n",
              "      <td>2.622802</td>\n",
              "      <td>68.226446</td>\n",
              "      <td>4.966202</td>\n",
              "      <td>17.017615</td>\n",
              "      <td>14.637203</td>\n",
              "      <td>0.045710</td>\n",
              "      <td>93.537604</td>\n",
              "      <td>0.241248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>258.920111</td>\n",
              "      <td>1.559118</td>\n",
              "      <td>0.008138</td>\n",
              "      <td>1.973405</td>\n",
              "      <td>45.080610</td>\n",
              "      <td>4.882070</td>\n",
              "      <td>12.125657</td>\n",
              "      <td>31.527678</td>\n",
              "      <td>0.102263</td>\n",
              "      <td>61.337594</td>\n",
              "      <td>0.246673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>512.880041</td>\n",
              "      <td>1.534643</td>\n",
              "      <td>0.006851</td>\n",
              "      <td>3.831437</td>\n",
              "      <td>85.223371</td>\n",
              "      <td>6.868614</td>\n",
              "      <td>31.013444</td>\n",
              "      <td>174.547053</td>\n",
              "      <td>0.204576</td>\n",
              "      <td>123.354705</td>\n",
              "      <td>0.248146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        length digits_numb  ... no_latin_number no_latin_ratio\n",
              "                          mean        mean  ...            mean           mean\n",
              "toxic severe_toxic                          ...                               \n",
              "0     0             403.232954    2.629527  ...       93.537604       0.241248\n",
              "1     0             258.920111    1.559118  ...       61.337594       0.246673\n",
              "      1             512.880041    1.534643  ...      123.354705       0.248146\n",
              "\n",
              "[3 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nUvnT9IAa_2",
        "colab_type": "text"
      },
      "source": [
        "Мы можем наблюдать, что не бывает очень токсичных комментариев со значением toxic=0, что понятно. \n",
        "\n",
        "1) Наименьшая длина у просто токсичных комментариев, наибольшая - у токсичных.\n",
        "2) Цифр больше в нетоксичных комментариях, у токсичных - сопоставимо\n",
        "3) Наименьшая доля цифр в очень токсичных комментариях\n",
        "4) Меньше всего строк в просто токсичных комментариях, а больше всего в очень токсичных\n",
        "5) Меньше слов в токсичных, больше - в очень токсичных\n",
        "6) Самые длинные слова в очень токсичных комментариях. В нетоксичных и просто токсичных длины слов сопоставимы\n",
        "7) В очень токсичных комментариях больше знаков пунктуации (возможно \"!\" или \"?\")\n",
        "8) Значительно больше слов в верхнем регистре в очень токсичных комментариях\n",
        "9) Доля слов в верхнем регистре также растет со степенью токсичности\n",
        "10) Меньше всего нелатинских символов в токсичных комментариях, а больше всего - в очень токсичных (возможно это какие-нибудь цензурные \"*\" как в \"f**k\")\n",
        "11) Доля латинских символов сопоставима, незначительно растет со степенью токсичности"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOu5VUd3CLS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "a36fa268-7efc-47dd-bfa7-3746b31a3b78"
      },
      "source": [
        "for text in quora[(quora['toxic']==1) & (quora['severe_toxic']==0)]['comment_text'][:3]:\n",
        "  print(text)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ":You might like to consider that I don't give a shit what you do or think.\n",
            "Uncle Tom House Niggers\n",
            "Bunch of morons should go **** themselves \n",
            "\n",
            "WESTBORO BAPTIST CHURCH ARE A F***** DISGRACE TO THE CHRISTIAN FAITH! HOW DARE THEY BE SO F***** SATANIC TO HOLD PROTESTS AT SOLDIERS' FUNERALS! THOSE CUNTS NEED SORTING OUT!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAO5gEFFCoME",
        "colab_type": "text"
      },
      "source": [
        "Если посмотреть на некоторые примеры сообщений, помеченных как токсичные (но не severe_toxic), не очень понятно почему последнее сообщение в верхнем регистре не относится к очень токсичным. Первые 3 примера токсичны, но действительно достаточно \"сдержанные\" и короткие."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QHIFtK0DN7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "70d9b624-431a-4690-9f89-7aa077f9ba97"
      },
      "source": [
        "for text in quora[(quora['toxic']==1) & (quora['severe_toxic']==1)]['comment_text'][:3]:\n",
        "  print(text)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "how bout \n",
            "\n",
            "you fuck off\n",
            "You're not an admin \n",
            "\n",
            "You act like an admin, but you're not an admin. Don't even fucking act like that. You're trying to fuck me up but you can't do any shit like that. As a sofa lands on the ground, your mother gets her tits squashed and dies and a dead rabbit falls from the clouds and lands on your ass, licking your ass. User:Factual80man\n",
            "CardinalDanFUCK YOU FAGGOT NIGGER CUNT LICKING CHINK DIPFUCKING SHIT NIGGER FACE, GET A LIFE OTHER THEN DELETING SHIT OFF WIKI YOU NERD FAGGOT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVLgnAJmDVQl",
        "colab_type": "text"
      },
      "source": [
        "На этих примерах очень токсичных сообщений можно действительно убедиться, что они более многословны и в них больше переводов строк"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iU_7F5zDo3n",
        "colab_type": "text"
      },
      "source": [
        "####Toxic-obscene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFHevbluDxZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "bc90a181-8798-4636-ba12-74b23bbae9db"
      },
      "source": [
        "quora.groupby(['toxic', 'obscene'])['length', 'digits_numb', 'digits_ratio', 'lines', 'words_numb', 'words_mean_len', \n",
        "                      'punct_numb', 'caps_numb', 'caps_ratio', 'no_latin_number', 'no_latin_ratio'].agg(['mean'])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>digits_numb</th>\n",
              "      <th>digits_ratio</th>\n",
              "      <th>lines</th>\n",
              "      <th>words_numb</th>\n",
              "      <th>words_mean_len</th>\n",
              "      <th>punct_numb</th>\n",
              "      <th>caps_numb</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>no_latin_number</th>\n",
              "      <th>no_latin_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>402.834758</td>\n",
              "      <td>2.612700</td>\n",
              "      <td>0.008993</td>\n",
              "      <td>2.620259</td>\n",
              "      <td>68.152823</td>\n",
              "      <td>4.963903</td>\n",
              "      <td>16.999097</td>\n",
              "      <td>14.566795</td>\n",
              "      <td>0.045658</td>\n",
              "      <td>93.430329</td>\n",
              "      <td>0.241242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>541.662069</td>\n",
              "      <td>8.479310</td>\n",
              "      <td>0.010003</td>\n",
              "      <td>3.506897</td>\n",
              "      <td>93.820690</td>\n",
              "      <td>5.765437</td>\n",
              "      <td>23.455172</td>\n",
              "      <td>39.113793</td>\n",
              "      <td>0.063737</td>\n",
              "      <td>130.831034</td>\n",
              "      <td>0.243262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>290.553749</td>\n",
              "      <td>1.612274</td>\n",
              "      <td>0.007571</td>\n",
              "      <td>2.031091</td>\n",
              "      <td>50.743954</td>\n",
              "      <td>4.732863</td>\n",
              "      <td>13.551920</td>\n",
              "      <td>31.966064</td>\n",
              "      <td>0.093197</td>\n",
              "      <td>68.723633</td>\n",
              "      <td>0.243490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>274.564816</td>\n",
              "      <td>1.509483</td>\n",
              "      <td>0.008407</td>\n",
              "      <td>2.236645</td>\n",
              "      <td>46.985732</td>\n",
              "      <td>5.344091</td>\n",
              "      <td>14.082478</td>\n",
              "      <td>55.216983</td>\n",
              "      <td>0.127241</td>\n",
              "      <td>65.448234</td>\n",
              "      <td>0.249647</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   length digits_numb  ... no_latin_number no_latin_ratio\n",
              "                     mean        mean  ...            mean           mean\n",
              "toxic obscene                          ...                               \n",
              "0     0        402.834758    2.612700  ...       93.430329       0.241242\n",
              "      1        541.662069    8.479310  ...      130.831034       0.243262\n",
              "1     0        290.553749    1.612274  ...       68.723633       0.243490\n",
              "      1        274.564816    1.509483  ...       65.448234       0.249647\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Yyz8WDD4N8",
        "colab_type": "text"
      },
      "source": [
        "Здесь уже можно заметить, что обсценная лексика необязательно является маркером токсичности (можно вспомнить о степени табуированности такой лексики в разных культурах)\n",
        "\n",
        "1) Интересно, что больше символов в нетоксичных сообщениях с обсценной лексикой\n",
        "2) В нетоксичных сообщениях с обсценной лексикой также больше цифр (возможно их мало и это какие-то статистические выбросы)\n",
        "3) Доля цифр соответственно больше в нетоксичных сообщениях с обсценной лексикой\n",
        "4) Переводы строк чаще встречаются в нетоксичных сообщениях с обсценной лексикой\n",
        "5) В нетоксичных сообщениях с обсценной лексикой больше слов, на втором месте - нетоксичные комментарии без ругательств\n",
        "6) Наибольшая длина слов в нетоксичных текстах с ругательствами, наименьшая - в токсичных без ругательств\n",
        "7) В нетоксичных сообщениях с обсценной лексикой больше пунктуации, меньше пунктуации - в токсичных без ругательств\n",
        "8) Капсом чаще пишут в токсичных сообщениях с бранными словами, меньше - в обычных сообщениях (со значениями 0 и 0)\n",
        "9) Доля капса больше в токсичных нежели нетоксичных текстах\n",
        "10) Нелатинских символов(видимо, цифр) больше всего в нетоксичных текстах с бранью и обычных текстах\n",
        "11) Доля нелатинских символов везде сопоставима"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1pmTk9MFvPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "5ffaf274-d6a4-4955-9675-bcaa8e5efb37"
      },
      "source": [
        "for text in quora[(quora['toxic']==0) & (quora['obscene']==1)]['comment_text'][:3]:\n",
        "  print(text)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"\n",
            " Wow, serious stick-up-the-ass-itis. But seriously, thanks for getting me blocked. Always wanted to do it. Thought it might be fun for a while, but turns out all the admins are the same variety of lame: lazy fascist. Sound familiar? Anyway, seriously, since I'm taking a (permanent?) break from Wikipedia, just leave that info here. I'm very serious about following up on that since Frank O'Hara is a subject of research in non-toilet-backwoods-punchline style research. Ya'll have fun wasting your lives on futility while the sticks up your asses keep you from having the real kind of fun you should with crap like this. But seriously, let me know where you got that O'Hara info. I'd like to follow it up (I know you'll ignore me, it's your pattern, but thought I'd give it a try  do you need reading lessons or something, it's like you have paragraphs on auto and are unable to read what others say). Anyway, just a citation or something, \"\"Frank O'Hara hates beats found here:\"\" Citation is another shortcoming of yours, but please try. Thanks! Happy Thanksgiving!68.220.76.174  \"\n",
            "\"\n",
            "\n",
            " Hahaha \n",
            "\n",
            "Check this out:\n",
            "\n",
            "MickMacNee, an editor with a long history of block for disruptive behaviour [10], seems to have gone out of line in the last days. I don't mind him being defensive of an article he has written the major part about, and several users in the AfD discussion have been very much engaged in it, including myself. However, I object to the repated personal attacks and uncivil behaviour by the editor. His history is rather long, so I provide just a few selected diffs of uncivil comment and direct personal attacks during the last days 11, [12], [13], [14]. In the discussion on this page about a third user, he calls my arguments for not agreeing with him \"\"\"\"evasion, obfuscation, interuption and intentional deafness\"\". That is rather typical of his attitude in the AfD discussion where he agressively drives that everybody disagreeing with him are wrong. I've tried to point it out to him, [15] but with hindsight (given our infected history) it might have been better not to as I should have predicted how he would respond.[16] However, I'm far from alone in having that opinion. In the last days, several other editors have also commented on his behaviour [17], [18], [19], [20].Jeppiz (talk) \n",
            "\n",
            "That block log looks like something out of a Wiki-horror story...why has he not been given long blocks in the past? I would go for a longer-term block. Ks0stm (T•C•G)  \n",
            "A users block log is not (generally) an excuse to throw the book at him, this looks a bit silly if you ask me, a bit of a tit for tat heated discussion over a article for deletion discussion that is split down the middle, and nothing will come of it, I can't find a really uncivil comment, perhaps if you guys just edit different articles for a few days. Off2riorob (talk)  \n",
            "It goes without saying that everybody has different opinions, but I do think that \"\"one of the nastiest and most repugnant editors\"\", \"\"Either your comment was simply ignorant of the facts (like you characterisation of my POV), or you are simply trolling, either way, you are all out of credit here tbh\"\", \"\"I've got no idea what crappy papers you read\"\", \"\"It's up to you if you want to parrot everybody's delete opinion as if it makes you look like you know what you are on about, but it really doesn't.\"\" are not particularly civil. Neither is \"\"I have had it with your crap.\"\". In any case, I won't interact with the user again, I rather leave Wikipedia. As I pointed out, I'm far from alone in having made these observations.Jeppiz (talk)  \n",
            "Off2riorob, I tried your suggestion, in fact I didn't think I'd need to try, I didn't think I'd cross paths with Mick after this bout of abuse. But sure enough I did, and when I reported him for violation of a 1R measure in place on the Northern Ireland article, half of his defence was an assumption of bad faith against me. I guess if someone keeps an eye on him, he can't get too far out of hand. Alastairward (talk)  \n",
            "It is a bit of a rant, he is clearly very upset about the footie, and I am sorry you have been upset Jeppiz, he has gone now, probably off to bed, I'm sure one of the admins will have a strong word in his ear when he shows his face again. I myself have had a run in with him but he has grown on me, what can I say. Off2riorob (talk)  \n",
            "Seeing the diffs Alastairward provided, I cannot agree, even though I see that you stood up for him that time as well. This is a user who seems unable to deal with conflicting views and routinely resorts to personal abuse.Jeppiz (talk)  \n",
            "Nothing routine about it. Your behaviour and Alistair's are pretty similar, which is why they provoked similar responses eventually. If either of you wish me to lay out the full package of evidence for either of your extraordinarily sustained campaigns of tendentious behaviours, I am only too willing to oblige. MickMacNee (talk)  \n",
            "First of all, Alistair and I are not the only editors you've attacked and insulted, there are at least Grsz [21] and Kevin McE [22] just in the last few days. \n",
            "While I have definitely argued with you, I have not called you one of \"\"the most repugnant editors\"\" [23], called your contributions \"\"crap\"\",[24] called you a \"\"lying hypocritical cunt\"\" [25] or told you to \"\"fuck off\"\" [26], [27]. \n",
            "Every time someone brings your behaviour to the attention of administrators, you come up with these vague and unsupported accusations that ones you've argued with have behaved in the same way. It is not a defense (then both should be blocked), and it's not true either, just a dishonest way for you to try to talk you out of it. I'm getting tired of having that same accusation thrown at me all the time and I take it as\n",
            "You reported me to AIV? Hilarious. That's one of the dick moves Werieth pulled too. Although he only did it as he knew reporting me to SPI would have probably brought him to much attention - at that stage he was still trying to keep the whole thing quiet, as it obviously benefited him. Not that he need have worried - every admin that ever responded to him, either at SPI or AIV, took the exact same view of my socking as as you espouse here (although obviously some were motivated by more than just incompetence). As such, it's likely your report to AIV is only going to ensure their names don't get picked up and the systems/attitudes/culture that cause this obviously counter-productive reaction don't get fixed - meaning that Werieth might as well try his arm at another return later. It speaks volumes that you'd think reverting me was remotely a good thing, even though in that very same ANI there's an arb explaining how he could have probably picked up on this whole thing much earlier if it wasn't for just that sort of mindless cycle of reversion and blocking of obvious socks, on the basis all socking is ebil. It's beyond idiotic.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg9KK8a2GNP1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b11bfd65-562a-46bd-8f74-5b67e79c35ce"
      },
      "source": [
        "len(quora[(quora['toxic']==0) & (quora['obscene']==1)])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgqOjbw3GReR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "245e583a-0a29-41e9-f941-f89ca85d1a80"
      },
      "source": [
        "len(quora[(quora['toxic']==1) & (quora['obscene']==1)])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1nQ_pfUF79r",
        "colab_type": "text"
      },
      "source": [
        "В примерах нетоксичных текстов с обсценной лексикой мы сразу может видеть комментарий, похожий на выброс. Он очень длинный, в нем есть цифры, а ругательства приведены в кавычках. Количество таких сообщений действительно значительно меньше, чем токсичных с обсценной лексикой"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_it3Ci5AGyOO",
        "colab_type": "text"
      },
      "source": [
        "####Toxic-threat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFVpnbs5G22H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "ec55784d-09e9-429b-89be-a6aa975d7df3"
      },
      "source": [
        "quora.groupby(['toxic', 'threat'])['length', 'digits_numb', 'digits_ratio', 'lines', 'words_numb', 'words_mean_len', \n",
        "                      'punct_numb', 'caps_numb', 'caps_ratio', 'no_latin_number', 'no_latin_ratio'].agg(['mean'])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>digits_numb</th>\n",
              "      <th>digits_ratio</th>\n",
              "      <th>lines</th>\n",
              "      <th>words_numb</th>\n",
              "      <th>words_mean_len</th>\n",
              "      <th>punct_numb</th>\n",
              "      <th>caps_numb</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>no_latin_number</th>\n",
              "      <th>no_latin_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th>threat</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>403.268119</td>\n",
              "      <td>2.629747</td>\n",
              "      <td>0.008996</td>\n",
              "      <td>2.622981</td>\n",
              "      <td>68.231994</td>\n",
              "      <td>4.966332</td>\n",
              "      <td>17.019180</td>\n",
              "      <td>14.638096</td>\n",
              "      <td>0.045705</td>\n",
              "      <td>93.545221</td>\n",
              "      <td>0.241244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>129.769231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.008504</td>\n",
              "      <td>1.230769</td>\n",
              "      <td>25.076923</td>\n",
              "      <td>3.952438</td>\n",
              "      <td>4.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.088692</td>\n",
              "      <td>34.307692</td>\n",
              "      <td>0.272078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>280.333044</td>\n",
              "      <td>1.584973</td>\n",
              "      <td>0.008125</td>\n",
              "      <td>2.133584</td>\n",
              "      <td>48.378569</td>\n",
              "      <td>5.069947</td>\n",
              "      <td>13.730131</td>\n",
              "      <td>42.938272</td>\n",
              "      <td>0.110102</td>\n",
              "      <td>66.515239</td>\n",
              "      <td>0.246710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>337.486667</td>\n",
              "      <td>0.586667</td>\n",
              "      <td>0.004457</td>\n",
              "      <td>2.426667</td>\n",
              "      <td>60.496667</td>\n",
              "      <td>4.792355</td>\n",
              "      <td>17.556667</td>\n",
              "      <td>98.176667</td>\n",
              "      <td>0.161103</td>\n",
              "      <td>82.300000</td>\n",
              "      <td>0.250140</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  length digits_numb  ... no_latin_number no_latin_ratio\n",
              "                    mean        mean  ...            mean           mean\n",
              "toxic threat                          ...                               \n",
              "0     0       403.268119    2.629747  ...       93.545221       0.241244\n",
              "      1       129.769231    0.923077  ...       34.307692       0.272078\n",
              "1     0       280.333044    1.584973  ...       66.515239       0.246710\n",
              "      1       337.486667    0.586667  ...       82.300000       0.250140\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owYrhCccG8ql",
        "colab_type": "text"
      },
      "source": [
        "Для этой пары тональностей тоже можно сделать интересное наблюдение: бывают нетоксичные сообщения с угрозами.\n",
        "1) Наименьшая посимвольная длина у нетоксичных комментариев с угрозами (возможно здесь снова выбросы). Наибольшая - у нейтральных\n",
        "2) Больше всего цифр в обычных сообщениях, меньше всего в токсичных с угрозами\n",
        "3) Доля цифр везде похожа, кроме токсичных комментариев с угрозами (там она меньше)\n",
        "4) Меньше всего переводов строк в нетоксичных комментариях с угрозами, у остальных этот показатель похожий\n",
        "5) Самые многословные комментарии - нейтральные, меньше всего слов у нетоксичных угроз (скорее всего их мало и это выбросы)\n",
        "6) Меньшая длина слов в нетоксичных комментариях с угрозами, наибольшая - у токсичных без угроз\n",
        "7) Меньше пунктуации в нетоксичных текстах с угрозами, похожее значение - у нейтральных и токсичных с угрозами\n",
        "8) Больше всего капса у токсичных комментариев с угрозами и у токсичных без угроз. Меньше всего - у нетоксичных с угрозами\n",
        "9) Доля капса растет с количеством угроз и токсичностью\n",
        "10) Меньше всего нелатинсих символов в нетоксичных комментариях с угрозами, а больше всего - в обычных\n",
        "11) Доля нелатинских символов сопоставимая во всех колонках"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq8cmaqdIwec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c7a9f42e-8465-4d0f-a6e9-234e13ee0dc6"
      },
      "source": [
        "for text in quora[(quora['toxic']==0) & (quora['threat']==1)]['comment_text'][:3]:\n",
        "  print(text)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "personal attacks \n",
            "\n",
            "dont tell me what i can and can not do i'll come over there right now and throw a brick through ur window\n",
            "I'ma smack ya upside da head wit a shovel. \n",
            "\n",
            "I'm takin ya down, boi.\n",
            "I KNOW IT'S ENGLAND BECAUSE IT SAYS UTC \n",
            "\n",
            "IN FACT I'LL BLOW UP UK AND IRELAND!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk2Rh9EPJIjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5be1f423-c2a4-4777-a6bc-258ee1dc487a"
      },
      "source": [
        "len( quora[(quora['toxic']==0) & (quora['threat']==1)])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYhWUyj1PrfK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "10df41ed-30a4-40ad-d734-8e9e38eaa5b6"
      },
      "source": [
        "len( quora[(quora['toxic']==1) & (quora['threat']==1)])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr6vBwByI56b",
        "colab_type": "text"
      },
      "source": [
        "Сложно судить, почему, например, угроза разбить окно кирпичом не является токсичной. Или \"I'LL BLOW UP UK AND IRELAND\" возможно кто-то трактует метафорически. \"I'm takin ya down, boi\" в контексте состязательного спорта не так уж и токсично. Таких сообщений(нетоксичных с угрозами) всего 13 и это явные статистические выбросы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Qy9HjZJatx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "bfd28950-efee-43b1-edb2-cee05c95131e"
      },
      "source": [
        "for text in quora[(quora['toxic']==1) & (quora['threat']==0)]['comment_text'][:3]:\n",
        "  print(text)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ":You might like to consider that I don't give a shit what you do or think.\n",
            "Uncle Tom House Niggers\n",
            "Bunch of morons should go **** themselves \n",
            "\n",
            "WESTBORO BAPTIST CHURCH ARE A F***** DISGRACE TO THE CHRISTIAN FAITH! HOW DARE THEY BE SO F***** SATANIC TO HOLD PROTESTS AT SOLDIERS' FUNERALS! THOSE CUNTS NEED SORTING OUT!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHwpoaB9JeyZ",
        "colab_type": "text"
      },
      "source": [
        "Токсичные сообщения с угрозами проще представить. Они больше нацелены на оскорбление или identity hate. Примеры, это иллюстрируют"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWuZYU06KXgg",
        "colab_type": "text"
      },
      "source": [
        "####Toxic-insult"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov3YCrR7Kiut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "ffb7aa2f-7ef8-422b-f856-ae3502f9666b"
      },
      "source": [
        "quora.groupby(['toxic', 'insult'])['length', 'digits_numb', 'digits_ratio', 'lines', 'words_numb', 'words_mean_len', \n",
        "                      'punct_numb', 'caps_numb', 'caps_ratio', 'no_latin_number', 'no_latin_ratio'].agg(['mean'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>digits_numb</th>\n",
              "      <th>digits_ratio</th>\n",
              "      <th>lines</th>\n",
              "      <th>words_numb</th>\n",
              "      <th>words_mean_len</th>\n",
              "      <th>punct_numb</th>\n",
              "      <th>caps_numb</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>no_latin_number</th>\n",
              "      <th>no_latin_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th>insult</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>403.304287</td>\n",
              "      <td>2.611610</td>\n",
              "      <td>0.008994</td>\n",
              "      <td>2.623387</td>\n",
              "      <td>68.237874</td>\n",
              "      <td>4.963690</td>\n",
              "      <td>17.020170</td>\n",
              "      <td>14.591430</td>\n",
              "      <td>0.045648</td>\n",
              "      <td>93.539988</td>\n",
              "      <td>0.241263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>380.261981</td>\n",
              "      <td>8.399361</td>\n",
              "      <td>0.009395</td>\n",
              "      <td>2.434505</td>\n",
              "      <td>64.546326</td>\n",
              "      <td>5.775068</td>\n",
              "      <td>16.194888</td>\n",
              "      <td>29.376997</td>\n",
              "      <td>0.065793</td>\n",
              "      <td>92.769968</td>\n",
              "      <td>0.236286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>292.800224</td>\n",
              "      <td>1.701646</td>\n",
              "      <td>0.008376</td>\n",
              "      <td>2.165357</td>\n",
              "      <td>50.725776</td>\n",
              "      <td>4.781350</td>\n",
              "      <td>13.730640</td>\n",
              "      <td>37.875047</td>\n",
              "      <td>0.099158</td>\n",
              "      <td>69.214179</td>\n",
              "      <td>0.247268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>271.031379</td>\n",
              "      <td>1.411499</td>\n",
              "      <td>0.007665</td>\n",
              "      <td>2.118189</td>\n",
              "      <td>46.703871</td>\n",
              "      <td>5.344197</td>\n",
              "      <td>13.945321</td>\n",
              "      <td>51.138106</td>\n",
              "      <td>0.123971</td>\n",
              "      <td>64.693912</td>\n",
              "      <td>0.246343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  length digits_numb  ... no_latin_number no_latin_ratio\n",
              "                    mean        mean  ...            mean           mean\n",
              "toxic insult                          ...                               \n",
              "0     0       403.304287    2.611610  ...       93.539988       0.241263\n",
              "      1       380.261981    8.399361  ...       92.769968       0.236286\n",
              "1     0       292.800224    1.701646  ...       69.214179       0.247268\n",
              "      1       271.031379    1.411499  ...       64.693912       0.246343\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-2ZIbOdKnLk",
        "colab_type": "text"
      },
      "source": [
        "Здесь мы можем наблюдать, что бывают нетоксичные оскорбления.\n",
        "1)  Посимвольная длина сообщения уменьшается по мере увеличения оскорблений и токсичности\n",
        "2) Больше всего цифр в нетоксичных сообщениях (особенно в тех, что с оскорблениями)\n",
        "3) Доля цифр также выше в нетоксичных сообщениях\n",
        "4) Больше всего строк в обычных сообщениях. Меньше всего - в токсичных с оскорблениями\n",
        "5) Число слов уменьшается по мере увеличения оскорблений и токсичности\n",
        "6) Наибольшая длина слов в сообщениях с оскорблениями. Наименьшая - в токсичных без оскорблений\n",
        "7) Больше всего пунктуации в нетоксичных сообщениях\n",
        "8-9) Количество букв в верхнем регистре и их доля прямо пропорциональны токсичности и наличию оскорблений\n",
        "10-11) Нелатинские символы чаще встречаются в нетоксичных сообщениях. Доля же таких символов сопоставима, но также меньше в нетоксичных текстах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E56HJ31Jhb-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "288158f3-738d-4833-fcaf-e07a519dff41"
      },
      "source": [
        "for text in quora[(quora['toxic']==0) & (quora['insult']==1)]['comment_text'][:3]:\n",
        "  print(text)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"\n",
            "\n",
            " Hindu Vandal \n",
            "\n",
            "YOu are a confirment Upper caste hindu vandal.  Morally corrupt as you are; you must be a Bhramin. You are a Confirmed sock puppeteer. You have been going around with another user name \"\"Netaji\"\" \"\n",
            "don't vandalize, please!\n",
            "\n",
            "your reversion of my edits constitutes as vandalism, because I wasn't vandalizing myself! please don't do it again, or you may get banned.\n",
            "\n",
            "also, just because your wife is a black latina doesn't mean yuh need to start braggin' about dat pum pum all over the place. did you marry her because you love her, or because she was a black pum pum latina? racist coward... 216.102.76.54\n",
            "Dear Josiah,\n",
            "\n",
            "2 random blaggards named Bastin and John Carter have repeatedly vandalized my page and I solemnly think it needs to stop! They keep on insulting my intelligence and from what I have heard you are a good administrator who helps people out! The best way you can help me is to block these fools immediately!\n",
            "\n",
            "Lots of Love,\n",
            "God bless,\n",
            "\n",
            "12th Doctor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9a-p4eSNcPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f1aa1dbc-139e-40f7-d2e4-9d8dde14b631"
      },
      "source": [
        "len(quora[(quora['toxic']==0) & (quora['insult']==1)])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "313"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcCQFoQoPlF2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b83f90f5-5791-4073-8e16-315550c5778e"
      },
      "source": [
        "len(quora[(quora['toxic']==1) & (quora['insult']==1)])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5322"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_jjgQ65OZz1",
        "colab_type": "text"
      },
      "source": [
        "Нетоксичных сообщений с оскорблениями всего 313.  В последнем автор оскорбляет кого-то в 3-м лице, кто портит его страницу, и просит о помощи. Действительно, нельзя однозначно сказать, что оно токсично. Во втором кого-то называют \"racist coward\". Мне кажется, это вполне токсично, но возможно всё не так однозначно. В первом случае кого-то называют вандалом и критикуют моральные качества. Наверное это может быть обидно, но всё же не совсем токсично"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhvjdcFJPJ1F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "b97fe08a-e89f-46c2-a370-89ef80f32abd"
      },
      "source": [
        "for text in quora[(quora['toxic']==1) & (quora['insult']==0)]['comment_text'][:3]:\n",
        "  print(text)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uncle Tom House Niggers\n",
            "how bout \n",
            "\n",
            "you fuck off\n",
            "Cesc Fabregas \n",
            "\n",
            "I see it's been changed that he now plays for Chelsea. Looks like I was right all along, how do you like that you little bitch? I was right and you were wrong.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBIaSnoiPZew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fbff3414-06db-4161-8930-475cae8b8b62"
      },
      "source": [
        "len(quora[(quora['toxic']==1) & (quora['insult']==0)])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5346"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hBHjsGNPViY",
        "colab_type": "text"
      },
      "source": [
        "Примеры иллюстрируют, что токсичные комментарии могут не содержать прямых оскорблений. Во всех них используется обсценная лексика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5lUKSjlQjFy",
        "colab_type": "text"
      },
      "source": [
        "####Toxic-identity_hate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNAostpZlA4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "a88866d9-629c-4934-bbb3-bc031ff68594"
      },
      "source": [
        "quora.groupby(['toxic', 'identity_hate'])['length', 'digits_numb', 'digits_ratio', 'lines', 'words_numb', 'words_mean_len', \n",
        "                      'punct_numb', 'caps_numb', 'caps_ratio', 'no_latin_number', 'no_latin_ratio'].agg(['mean'])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>digits_numb</th>\n",
              "      <th>digits_ratio</th>\n",
              "      <th>lines</th>\n",
              "      <th>words_numb</th>\n",
              "      <th>words_mean_len</th>\n",
              "      <th>punct_numb</th>\n",
              "      <th>caps_numb</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>no_latin_number</th>\n",
              "      <th>no_latin_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxic</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>403.215713</td>\n",
              "      <td>2.629522</td>\n",
              "      <td>0.008996</td>\n",
              "      <td>2.622990</td>\n",
              "      <td>68.222156</td>\n",
              "      <td>4.966133</td>\n",
              "      <td>17.018063</td>\n",
              "      <td>14.636737</td>\n",
              "      <td>0.045700</td>\n",
              "      <td>93.535982</td>\n",
              "      <td>0.241261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>428.478261</td>\n",
              "      <td>2.637681</td>\n",
              "      <td>0.008187</td>\n",
              "      <td>2.347826</td>\n",
              "      <td>74.507246</td>\n",
              "      <td>5.067452</td>\n",
              "      <td>16.362319</td>\n",
              "      <td>15.318841</td>\n",
              "      <td>0.060495</td>\n",
              "      <td>95.913043</td>\n",
              "      <td>0.222899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>279.760473</td>\n",
              "      <td>1.508389</td>\n",
              "      <td>0.008141</td>\n",
              "      <td>2.087288</td>\n",
              "      <td>48.652187</td>\n",
              "      <td>4.872934</td>\n",
              "      <td>14.097272</td>\n",
              "      <td>41.415028</td>\n",
              "      <td>0.107499</td>\n",
              "      <td>67.104169</td>\n",
              "      <td>0.247423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>304.161595</td>\n",
              "      <td>2.051417</td>\n",
              "      <td>0.006804</td>\n",
              "      <td>2.697796</td>\n",
              "      <td>49.403987</td>\n",
              "      <td>6.990933</td>\n",
              "      <td>11.192025</td>\n",
              "      <td>75.855194</td>\n",
              "      <td>0.152700</td>\n",
              "      <td>65.480588</td>\n",
              "      <td>0.240526</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         length digits_numb  ... no_latin_number no_latin_ratio\n",
              "                           mean        mean  ...            mean           mean\n",
              "toxic identity_hate                          ...                               \n",
              "0     0              403.215713    2.629522  ...       93.535982       0.241261\n",
              "      1              428.478261    2.637681  ...       95.913043       0.222899\n",
              "1     0              279.760473    1.508389  ...       67.104169       0.247423\n",
              "      1              304.161595    2.051417  ...       65.480588       0.240526\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg7io55PQ17s",
        "colab_type": "text"
      },
      "source": [
        "Мы можем наблюдать, что identity hate может встречаться в нетоксичных сообщениях\n",
        "\n",
        "1) Длина комментариев больше в нетоксичных текстах\n",
        "2-3) Наименьшее число цифр в токсичных сообщениях. Доля же цифр значительно меньше в токсичных сообщениях с ненавистью к социальным классам\n",
        "4) Наибольшее число строк в нейтральных сообщениях и в токсичных с ненавистью к классам\n",
        "5) В нетоксичных комментариях больше слов\n",
        "6) Самые длинные слова в комментариях с identity_hate (видимо, там чаще встречаются такие слова как \"communist\", \"homosexual\", \"christian\" и они обычно длиннее)\n",
        "7)В нетоксичных сообщениях больше пунктуации\n",
        "8-9) Число символов в верхнем регистре и их доля растут вместе с токсичностью и разжиганием ненависти\n",
        "10-11)Число нелатинских символов уменьшается вместе с токсичностью. Наименьшая их доля в нетоксичных текстах с разжиганием ненависти"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdbRl6Q4SbAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "b77c9b86-85c6-4992-e2d6-e3865b9f8a87"
      },
      "source": [
        "for text in quora[(quora['toxic']==0) & (quora['identity_hate']==1)]['comment_text'][:3]:\n",
        "  print(text)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jewish \n",
            "\n",
            "Please dont think that jews are everyone just based on your claims. Also dont think jews are smart. if you think so, you are making a clown out of yourself..\n",
            "This game is really popular with white racist people in Texas.\n",
            "\"::::::::::\"\"During slavery and Jim Crow, race was used to justify the law treating those superior blacks as inferiors.\"\" Whereas, now, race is used to justify treating possibly inferior blacks as equals, without evidence, which is just as unfair. I imagine you'll have some histrionic fit \"\"OMG, he's a racist\"\", but like I said, there is no evidence races are equal, in terms of wealth generation. 128.40.97.30  \n",
            "\n",
            "\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS4ji80qSYKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b504913a-95c9-4200-f066-02a327aab59f"
      },
      "source": [
        "len(quora[(quora['toxic']==0) & (quora['identity_hate']==1)])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwVbluovSnEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "45925c05-c9a6-4bd4-bf55-5783293bc955"
      },
      "source": [
        "len(quora[(quora['toxic']==1) & (quora['identity_hate']==1)])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "953"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku8MP_kmSpCh",
        "colab_type": "text"
      },
      "source": [
        "Доля нетоксичных текстов с разжиганием ненависти не очень высока. Все эти примеры связаны с расизмом. В первом говорится об интеллекте евреев, во втором про популярную игру у расистов в Техасе(не понятен контекст) и в третьем высказывается мнение \"there is no evidence races are equal, in terms of wealth generation\", которое может подводить к ненависти к социальным группам, хотя нет каких-то прямых призывов или оскорблений. Т.е. все эти примеры, это обсуждения непростых тем \"на грани фола\", наверное они действительно всё же нетоксичны. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A07k9T-MlbQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "c437d1db-37c3-49ac-acf7-3a88ca80c1a7"
      },
      "source": [
        "for text in quora[(quora['toxic']==1) & (quora['identity_hate']==0)]['comment_text'][:3]:\n",
        "  print(text)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ":You might like to consider that I don't give a shit what you do or think.\n",
            "how bout \n",
            "\n",
            "you fuck off\n",
            "Cesc Fabregas \n",
            "\n",
            "I see it's been changed that he now plays for Chelsea. Looks like I was right all along, how do you like that you little bitch? I was right and you were wrong.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRScifZtlxyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "953d5ef7-9f77-4cec-9539-60fc08bbab6e"
      },
      "source": [
        "len(quora[(quora['toxic']==1) & (quora['identity_hate']==0)])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXQVvhGaUG2S",
        "colab_type": "text"
      },
      "source": [
        "Примеров токсичных сообщений без разжигания ненависти много и это вполне понятно. Чтобы кого-то оскорбить или поругать, необязательно вспоминать его расу, политические взгляды или ориентацию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aMZgFZPjQC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# среднее значение колонки\n",
        "weather_hist['temp'].mean(), weather_hist['temp'].std()\n",
        "\n",
        "\n",
        "\n",
        "weather_hist['temp_app'].min(), weather_hist['temp_app'].max()\n",
        "\n",
        "weather_hist.describe()\n",
        "weather_hist.info()\n",
        "weather_hist.corr()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF3LhbsEbM2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#тепловая карта\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "sns.heatmap(data=weather_hist.corr(), \n",
        "            annot=True, ax=ax)\n",
        "plt.title(\"Корреляция\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lisGeQ71bYQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax = sns.boxplot(data=weather_hist[['temp', 'temp_app']])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBKnPXey_KNW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "7f9053c8-b188-4bda-fa3b-6346fc5b1f56"
      },
      "source": [
        "quora"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223544</th>\n",
              "      <td>fff8f64043129fa2</td>\n",
              "      <td>:Jerome, I see you never got around to this…! ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223545</th>\n",
              "      <td>fff9d70fe0722906</td>\n",
              "      <td>==Lucky bastard== \\n http://wikimediafoundatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223546</th>\n",
              "      <td>fffa8a11c4378854</td>\n",
              "      <td>==shame on you all!!!== \\n\\n You want to speak...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223547</th>\n",
              "      <td>fffac2a094c8e0e2</td>\n",
              "      <td>MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223548</th>\n",
              "      <td>fffb5451268fb5ba</td>\n",
              "      <td>\" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>223549 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... identity_hate\n",
              "0       0000997932d777bf  ...             0\n",
              "1       000103f0d9cfb60f  ...             0\n",
              "2       000113f07ec002fd  ...             0\n",
              "3       0001b41b1c6bb37e  ...             0\n",
              "4       0001d958c54c6e35  ...             0\n",
              "...                  ...  ...           ...\n",
              "223544  fff8f64043129fa2  ...             0\n",
              "223545  fff9d70fe0722906  ...             0\n",
              "223546  fffa8a11c4378854  ...             0\n",
              "223547  fffac2a094c8e0e2  ...             0\n",
              "223548  fffb5451268fb5ba  ...             0\n",
              "\n",
              "[223549 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0mMdNjm8ABd",
        "colab_type": "text"
      },
      "source": [
        "##Бейзлайн модель из sklearn (векторайзер + модель) с отбором признаков (через l1 регуляризацию, на глаз через анализ важных параметров или через permutation importance) - 2 балл\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs928vpK-71K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(quora.comment_text)\n",
        "y = quora.toxic.values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgVxNjYJQVgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c8510fb1-028e-49a1-eca4-20860901adf4"
      },
      "source": [
        "X_train.size"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4553347"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAqu1JsKAsFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_model = linear_model.LogisticRegression(max_iter=50000)\n",
        "reg_model = reg_model.fit(X_train, y_train)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6GnvE85ywTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1aadde53-95bf-4f8e-ff25-382f9dde7622"
      },
      "source": [
        "y_pred = reg_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, output_dict=True)['accuracy'])"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9506172839506173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBOZBkpX1ePp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9e716d53-06df-463d-dfd8-099d7ea9487f"
      },
      "source": [
        "y_pred = reg_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      5029\n",
            "           1       0.80      0.68      0.73       560\n",
            "\n",
            "    accuracy                           0.95      5589\n",
            "   macro avg       0.88      0.83      0.85      5589\n",
            "weighted avg       0.95      0.95      0.95      5589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOHmxhKzVxsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0a4cfeca-9515-4094-d7ea-f6848691f3a5"
      },
      "source": [
        "test_preds = reg_model.predict_proba(X_test)[:, 1]\n",
        "print('result on test: {}'.format(roc_auc_score(y_test,test_preds)))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result on test: 0.9489233872113173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypGJFSlFL9Nu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f19d2c9c-2e13-4a95-e6e3-560e9bd286a4"
      },
      "source": [
        "all_weights=eli5.formatters.as_dataframe.explain_weights_df(reg_model)\n",
        "len(all_weights)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "167033"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP77R1b2yvmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top_features(model, n):\n",
        "  weights = eli5.formatters.as_dataframe.explain_weights_df(model)\n",
        "  features = []\n",
        "  for weight in weights.feature[:n]:\n",
        "    if 'BIAS' not in weight:\n",
        "      feature = weight.strip('x')\n",
        "      features += [int(feature)]\n",
        "  return features"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88eZyx8m3XyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_features(features):\n",
        "  ind2word = {v:k for k,v in vectorizer.vocabulary_.items()}\n",
        "  for feature in features:\n",
        "    print(ind2word[feature])"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb3FJuXQzxJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_50 = top_features(reg_model, 50)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LKcxNha3p2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4d3b9353-47d7-4d86-a9c1-5935cf6065c9"
      },
      "source": [
        "show_features(top_50[:10])"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuck\n",
            "idiot\n",
            "asshole\n",
            "faggot\n",
            "shit\n",
            "stupid\n",
            "fucking\n",
            "fucker\n",
            "suck\n",
            "cunt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vHbyhlT_nKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def n_features_model(model, n): # запуск логистической регрессии с top n features, получаем accuracy\n",
        "  top_n = top_features(model, n)\n",
        "  X_train_eli5 = X_train[:,top_n]\n",
        "  X_test_eli5 = X_test[:,top_n]\n",
        "  eli5_model = linear_model.LogisticRegression(max_iter=50000)\n",
        "  eli5_model = eli5_model.fit(X_train_eli5, y_train)\n",
        "  test_preds = reg_model.predict_proba(X_test_eli5)[:, 1]\n",
        "print('result on test: {}'.format(roc_auc_score(y_test,test_preds)))\n",
        "  return float(classification_report(y_test, test_preds, output_dict=True)['accuracy'])"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG-fzjmKNiVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_acc(from_x, to, step):\n",
        "  current_score = 0 \n",
        "  for n in range(from_x, to, step):\n",
        "    score = n_features_model(reg_model, n)\n",
        "    if score>current_score:\n",
        "      current_score = score\n",
        "      number = n\n",
        "  print(\"best accuracy is {} with {} top features\".format(current_score, number))"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtMrEjJuN9mJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f2f4aff0-0863-463b-b8ee-d11f967755d0"
      },
      "source": [
        "best_acc(5000, 165000, 5000)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best accuracy is 0.9463231347289318 with 160000 top features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uou2_d5GpKe-",
        "colab_type": "text"
      },
      "source": [
        "Качество получилось хуже, чем без отбора features, поэтому рассмотрим еще более узкий диапазон"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2GgAjMsobxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f565a353-ce9f-4d8f-a452-449f07df79ed"
      },
      "source": [
        "best_acc(159000, 168000, 1000)  "
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best accuracy is 0.9513329754875649 with 166000 top features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnjfThbtv-K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Теперь качество стало на 0.1 % лучше"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcwqYOIFv04K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "466ea660-4da8-41bc-d602-3d9a0bcd57a9"
      },
      "source": [
        "best_acc(165500, 166500, 100)  "
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best accuracy is 0.9516908212560387 with 165900 top features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrAiMCiKG92S",
        "colab_type": "text"
      },
      "source": [
        "Accuracy получилось на 0.1% лучше, чем без отбора признаков.\n",
        "При sample = 0.01 получалось на 2.5% лучше, чем без отбора признаков (от 500 до 15000 с шагом 500, т.к. общее число признаков там меньше)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54Qc1RJO1zot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def n_features_model_report(model, n):\n",
        "  top_n = top_features(model, n)\n",
        "  X_train_eli5 = X_train[:,top_n]\n",
        "  X_test_eli5 = X_test[:,top_n]\n",
        "  eli5_model = linear_model.LogisticRegression(max_iter=50000)\n",
        "  eli5_model = eli5_model.fit(X_train_eli5, y_train)\n",
        "  test_preds = eli5_model.predict(X_test_eli5)\n",
        "  print(classification_report(y_test, test_preds))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iofRW73bAneU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "d5dac396-87c3-4205-f28f-2688e14ae7db"
      },
      "source": [
        "n_features_model_report(reg_model, 165900)"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      5029\n",
            "           1       0.82      0.66      0.73       560\n",
            "\n",
            "    accuracy                           0.95      5589\n",
            "   macro avg       0.89      0.82      0.85      5589\n",
            "weighted avg       0.95      0.95      0.95      5589\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdl_GePnWeSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "35aaaf54-2565-4ae1-9d96-eab9e2903b3b"
      },
      "source": [
        "top_n = top_features(reg_model, 165900)\n",
        "X_train_eli5 = X_train[:,top_n]\n",
        "X_test_eli5 = X_test[:,top_n]\n",
        "eli5_model = linear_model.LogisticRegression(max_iter=50000)\n",
        "eli5_model = eli5_model.fit(X_train_eli5, y_train)\n",
        "test_preds = eli5_model.predict_proba(X_test_eli5)[:, 1]\n",
        "print('result on test: {}'.format(roc_auc_score(y_test,test_preds)))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result on test: 0.9485528577109905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fotdzihO4nmT",
        "colab_type": "text"
      },
      "source": [
        "Если сравнивать по roc_auc_score, то получилось почти также (незначительно хуже)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI2pOTuQF_v2",
        "colab_type": "text"
      },
      "source": [
        "##Ансамбль из моделей в sklearn (ансамблевые модели типа randomforest не считаются). Нужно минимум 5 разных моделей - 2 балла"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTjTgdosb04v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = quora['comment_text']\n",
        "y = quora['toxic']"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdoCr3K1bXPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fse0JUA8LK_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m1 = linear_model.LogisticRegression()\n",
        "m2 = GaussianNB()\n",
        "m3 = DecisionTreeClassifier()\n",
        "m4 = SVC()\n",
        "m5 = MultinomialNB()\n",
        "\n",
        "vc = VotingClassifier(estimators=[\n",
        "        ('lr', m1), ('gnb', m2), ('dtc', m3), ('svc', m4), ('mnb', m5)], voting='hard')\n",
        "\n",
        "voting = Pipeline([\n",
        "    ('vect', CountVectorizer( analyzer='word', max_features=200)),\n",
        "    ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "    ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
        "    ('clf', vc),\n",
        "    ])\n",
        "\n",
        "voting = voting.fit(X_train, y_train)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR2eoviy37Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = voting.predict(X_test)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4x07J_pft0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "aa8c5aad-9079-451b-973b-93f9a0a776b4"
      },
      "source": [
        "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.89\n",
            "Recall:   0.64\n",
            "F1-measure:   0.70\n",
            "Accuracy:   0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kERzLcU4Z7O",
        "colab_type": "text"
      },
      "source": [
        "Accuracy получилось хуже, чем в бейзлайн модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Njy0rOUGCCO",
        "colab_type": "text"
      },
      "source": [
        "##Любая нейронная модель (минимум 5 слоев) с Dropout, Pooling и колбеками - 2 балла"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGOT5XkN0f4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize (text):\n",
        "  symbols = []\n",
        "  for symb in text:\n",
        "    symbols += [symb]  \n",
        "  return symbols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8s9mYUH0kPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "63e146d4-f44e-44a4-e7a2-5fd2d987e344"
      },
      "source": [
        "vocab = Counter()\n",
        "\n",
        "for text in quora.comment_text:\n",
        "  vocab.update(tokenize(text))\n",
        "\n",
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MBZiLvm5GBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c5c2c1f4-b9d5-46d2-8db7-cc01a841019d"
      },
      "source": [
        "filtered_vocab = set()\n",
        "\n",
        "for symb in vocab:\n",
        "    if vocab[symb] > 5:\n",
        "        filtered_vocab.add(symb)\n",
        "        \n",
        "len(filtered_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taenhI8k5f31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b7b07a48-556d-44ab-b2f5-5956302f8fd4"
      },
      "source": [
        "symb2id = {'UNK':1, 'PAD':0}\n",
        "\n",
        "for symb in filtered_vocab:\n",
        "    symb2id[symb] = len(symb2id)\n",
        "\n",
        "id2symb = {i:symb for symb, i in symb2id.items()}\n",
        "X = []\n",
        "\n",
        "for text in quora.comment_text:\n",
        "    tokens = tokenize(text)\n",
        "    ids = [symb2id.get(token, 1) for token in tokens]\n",
        "    X.append(ids)\n",
        "\n",
        "MAX_LEN = max(len(x) for x in X)\n",
        "MEAN_LEN = np.median([len(x) for x in X])\n",
        "MAX_LEN, MEAN_LEN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 203.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp5P9SQo6U5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = int(MEAN_LEN) + 5\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN)\n",
        "y = quora.toxic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlKLaj648I-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "878e09d1-2460-40d3-fd20-50625376c402"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111774, 208)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxVWYO4N-zNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "71cbf806-09e9-4e5f-fc3e-d1456c58f727"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111774,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWiOhUPU-vMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.5, stratify=y, random_state=42) # выше test_size был другой"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr6wOp2j_BTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.weights', \n",
        "                                                monitor='val_accuracy',\n",
        "                                                verbose=1,\n",
        "                                                save_weights_only=True,\n",
        "                                                save_best_only=True,\n",
        "                                                mode='max',\n",
        "                                                save_freq='epoch')\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                                              min_delta=0.01, \n",
        "                                              patience=10,\n",
        "                                              verbose=1, \n",
        "                                              mode='max',\n",
        "                                              )"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwtyqz46_Fze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(symb2id), output_dim=50)(inputs, )\n",
        "convs = []\n",
        "\n",
        "conv1 = tf.keras.layers.Conv1D(kernel_size=2, filters=24, strides=1)(embeddings)\n",
        "conv2 = tf.keras.layers.Conv1D(kernel_size=1, filters=16, strides=1, activation='relu')(conv1)\n",
        "pool1 = tf.keras.layers.GlobalMaxPooling1D()(conv2)\n",
        "drop1 = tf.keras.layers.Dropout(0.2)(pool1)\n",
        "convs.append(drop1)\n",
        "\n",
        "\n",
        "conv3 = tf.keras.layers.Conv1D(kernel_size=4, filters=32, strides=1)(embeddings)\n",
        "conv4 = tf.keras.layers.Conv1D(kernel_size=2, filters=28, strides=1)(conv3)\n",
        "conv5 = tf.keras.layers.Conv1D(kernel_size=1, filters=16, strides=1)(conv4)\n",
        "pool2 = tf.keras.layers.GlobalMaxPooling1D()(conv5)\n",
        "convs.append(pool2)\n",
        "\n",
        "conv6 = tf.keras.layers.Conv1D(kernel_size=5, filters=16, strides=1)(embeddings)\n",
        "conv7 = tf.keras.layers.Conv1D(kernel_size=3, filters=14, strides=1)(conv6)\n",
        "conv8 = tf.keras.layers.Conv1D(kernel_size=2, filters=16, strides=1)(conv7)\n",
        "drop2 = tf.keras.layers.GlobalMaxPooling1D()(conv8)\n",
        "convs.append(drop2)\n",
        "\n",
        "\n",
        "\n",
        "conv9 = tf.keras.layers.Conv1D(kernel_size=6, filters=32, strides=1)(embeddings)\n",
        "conv10 = tf.keras.layers.Conv1D(kernel_size=5, filters=32, strides=1)(conv9)\n",
        "conv11 = tf.keras.layers.Conv1D(kernel_size=4, filters=32, strides=1)(conv10)\n",
        "conv12 = tf.keras.layers.Conv1D(kernel_size=3, filters=16, strides=1)(conv11)\n",
        "drop3 = tf.keras.layers.GlobalMaxPooling1D()(conv12)\n",
        "convs.append(drop3)\n",
        "\n",
        "\n",
        "concat = tf.keras.layers.concatenate(convs)\n",
        "\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(concat)\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg6XNo4u_voE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "d7c036e5-c053-4645-c6e8-fd00c47d34dc"
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=500,\n",
        "         epochs=100,\n",
        "          callbacks = [checkpoint, early_stop])"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.9052\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.90710, saving model to model.weights\n",
            "112/112 [==============================] - 130s 1s/step - loss: 0.3001 - accuracy: 0.9052 - val_loss: 0.2647 - val_accuracy: 0.9071\n",
            "Epoch 2/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9225\n",
            "Epoch 00002: val_accuracy improved from 0.90710 to 0.92979, saving model to model.weights\n",
            "112/112 [==============================] - 130s 1s/step - loss: 0.2252 - accuracy: 0.9225 - val_loss: 0.2061 - val_accuracy: 0.9298\n",
            "Epoch 3/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.9321\n",
            "Epoch 00003: val_accuracy improved from 0.92979 to 0.93199, saving model to model.weights\n",
            "112/112 [==============================] - 130s 1s/step - loss: 0.1989 - accuracy: 0.9321 - val_loss: 0.1951 - val_accuracy: 0.9320\n",
            "Epoch 4/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9353\n",
            "Epoch 00004: val_accuracy improved from 0.93199 to 0.93292, saving model to model.weights\n",
            "112/112 [==============================] - 134s 1s/step - loss: 0.1888 - accuracy: 0.9353 - val_loss: 0.1940 - val_accuracy: 0.9329\n",
            "Epoch 5/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.9373\n",
            "Epoch 00005: val_accuracy improved from 0.93292 to 0.93376, saving model to model.weights\n",
            "112/112 [==============================] - 130s 1s/step - loss: 0.1785 - accuracy: 0.9373 - val_loss: 0.1935 - val_accuracy: 0.9338\n",
            "Epoch 6/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9398\n",
            "Epoch 00006: val_accuracy did not improve from 0.93376\n",
            "112/112 [==============================] - 130s 1s/step - loss: 0.1710 - accuracy: 0.9398 - val_loss: 0.1865 - val_accuracy: 0.9333\n",
            "Epoch 7/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1636 - accuracy: 0.9411\n",
            "Epoch 00007: val_accuracy improved from 0.93376 to 0.93533, saving model to model.weights\n",
            "112/112 [==============================] - 130s 1s/step - loss: 0.1636 - accuracy: 0.9411 - val_loss: 0.1820 - val_accuracy: 0.9353\n",
            "Epoch 8/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.9439\n",
            "Epoch 00008: val_accuracy improved from 0.93533 to 0.93541, saving model to model.weights\n",
            "112/112 [==============================] - 130s 1s/step - loss: 0.1584 - accuracy: 0.9439 - val_loss: 0.1811 - val_accuracy: 0.9354\n",
            "Epoch 9/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9447\n",
            "Epoch 00009: val_accuracy did not improve from 0.93541\n",
            "112/112 [==============================] - 134s 1s/step - loss: 0.1541 - accuracy: 0.9447 - val_loss: 0.1820 - val_accuracy: 0.9349\n",
            "Epoch 10/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.9467\n",
            "Epoch 00010: val_accuracy did not improve from 0.93541\n",
            "112/112 [==============================] - 129s 1s/step - loss: 0.1493 - accuracy: 0.9467 - val_loss: 0.1953 - val_accuracy: 0.9291\n",
            "Epoch 11/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9470\n",
            "Epoch 00011: val_accuracy improved from 0.93541 to 0.93737, saving model to model.weights\n",
            "112/112 [==============================] - 130s 1s/step - loss: 0.1473 - accuracy: 0.9470 - val_loss: 0.1841 - val_accuracy: 0.9374\n",
            "Epoch 12/100\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 0.9492\n",
            "Epoch 00012: val_accuracy did not improve from 0.93737\n",
            "112/112 [==============================] - 130s 1s/step - loss: 0.1424 - accuracy: 0.9492 - val_loss: 0.1874 - val_accuracy: 0.9360\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe195deb1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOLRafxE_H6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "9611a688-3870-49b7-fe19-afe72680998f"
      },
      "source": [
        "print(model.history.history.keys())\n",
        "plt.plot(model.history.history['accuracy'])\n",
        "plt.plot(model.history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oP7TciFLD0h",
        "colab_type": "text"
      },
      "source": [
        "Результат близок к бейзлайну, но всё равно хуже"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-Xh9l02GMsl",
        "colab_type": "text"
      },
      "source": [
        "##Использование нескольких видов эмбедингов в одной модели - 1.75 балла\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-qahqQ3J6t7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "5249b648-d605-425e-d656-233c71567bf8"
      },
      "source": [
        "!pip install eli5\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from collections import Counter\n",
        "import gensim\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import *\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import gensim.downloader as api\n",
        "\n",
        "import re \n",
        "from string import punctuation as punct\n",
        "gdrive = '/gdrive/My Drive/'\n",
        "path = gdrive + \"jigsaw-toxic-comment-train.csv\"\n",
        "quora = pd.read_csv(path)\n",
        "quora = quora.sample(frac=0.5, random_state=42)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: eli5 in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.18.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.15.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn1pihU7zrbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    tokens = text.lower().split()\n",
        "    tokens = [token.strip(punctuation) for token in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr0TRsL5zs-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Counter()\n",
        "\n",
        "for text in quora.comment_text:\n",
        "    vocab.update(preprocess(text))\n",
        "\n",
        "filtered_vocab = set()\n",
        "\n",
        "for word in vocab:\n",
        "    if vocab[word] > 4:\n",
        "        filtered_vocab.add(word)\n",
        "\n",
        "len(filtered_vocab)\n",
        "word2id = {'UNK':1, 'PAD':0}\n",
        "\n",
        "for word in filtered_vocab:\n",
        "    word2id[word] = len(word2id)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XwY2FpuzubZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word = {i:word for word, i in word2id.items()}\n",
        "X = []\n",
        "\n",
        "for text in quora.comment_text:\n",
        "    tokens = preprocess(text)\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X.append(ids)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7bZId-4z9HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = max(len(x) for x in X)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVvmYkpT0Eus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN)\n",
        "X.shape\n",
        "y = quora.toxic"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nekYociJ0OGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, random_state=42)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOj1s22lFk85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v = gensim.models.Word2Vec([preprocess(text) for text in quora.comment_text], size=100)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXVjfwsjnjBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ft = gensim.models.FastText([preprocess(text) for text in quora.comment_text], size=100)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3JscEaRrkdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "99cf2c55-7f9d-4ae7-9393-cdef27a1898e"
      },
      "source": [
        "glove = api.load(\"glove-wiki-gigaword-100\") # 2 модели обучим, а glove возьмем предобученную"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEqqqUAXnxY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_weights = np.zeros((len(w2v.wv.vocab)+2, 100))\n",
        "for i, vec in enumerate(w2v.wv.vectors): \n",
        "  w2v_weights[i+2] = w2v.wv[id2word[i+2]]  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8XtvPqGnzGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ft_weights = np.zeros((len(ft.wv.vocab)+2, 100))\n",
        "for i, vec in enumerate(ft.wv.vectors):\n",
        "  ft_weights[i+2] = ft.wv[id2word[i+2]]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZezibzxpCpe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2e9feffd-84b4-48b4-a2a7-9db612fdba5a"
      },
      "source": [
        "glove_weights = np.zeros((len(ft.wv.vocab)+2, 100))\n",
        "for i, vec in enumerate(ft.wv.vectors): \n",
        "  try:\n",
        "    glove_weights[i+2] = glove.wv[id2word[i+2]]\n",
        "  except KeyError:\n",
        "    glove_weights[i+2] = 0"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk-pe_3izgPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.weights', \n",
        "                                                monitor='val_accuracy',\n",
        "                                                verbose=1,\n",
        "                                                save_weights_only=True,\n",
        "                                                save_best_only=True,\n",
        "                                                mode='max',\n",
        "                                                save_freq='epoch')\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                                              min_delta=0.01, \n",
        "                                              patience=5,\n",
        "                                              verbose=1, \n",
        "                                              mode='max',\n",
        "                                              )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYK4nZ3qzUEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embedding1 = tf.keras.layers.Embedding(input_dim=len(w2v_weights), output_dim=100, weights=[w2v_weights])(inputs)\n",
        "embedding2 = tf.keras.layers.Embedding(input_dim=len(ft_weights), output_dim=100, weights=[ft_weights])(inputs)\n",
        "embedding3 = tf.keras.layers.Embedding(input_dim=len(glove_weights), output_dim=100, weights=[ft_weights])(inputs)\n",
        "embeddings = tf.keras.layers.Concatenate()([embedding1, embedding2, embedding3])\n",
        "convs = []\n",
        "\n",
        "conv1 = tf.keras.layers.Conv1D(kernel_size=2, filters=24, strides=1)(embeddings)\n",
        "conv2 = tf.keras.layers.Conv1D(kernel_size=1, filters=16, strides=1, activation='relu')(conv1)\n",
        "pool1 = tf.keras.layers.GlobalMaxPooling1D()(conv2)\n",
        "drop1 = tf.keras.layers.Dropout(0.2)(pool1)\n",
        "convs.append(drop1)\n",
        "\n",
        "\n",
        "conv3 = tf.keras.layers.Conv1D(kernel_size=4, filters=32, strides=1)(embeddings)\n",
        "conv4 = tf.keras.layers.Conv1D(kernel_size=2, filters=28, strides=1)(conv3)\n",
        "conv5 = tf.keras.layers.Conv1D(kernel_size=1, filters=16, strides=1)(conv4)\n",
        "pool2 = tf.keras.layers.GlobalMaxPooling1D()(conv5)\n",
        "convs.append(pool2)\n",
        "\n",
        "conv6 = tf.keras.layers.Conv1D(kernel_size=5, filters=16, strides=1)(embeddings)\n",
        "conv7 = tf.keras.layers.Conv1D(kernel_size=3, filters=14, strides=1)(conv6)\n",
        "conv8 = tf.keras.layers.Conv1D(kernel_size=2, filters=16, strides=1)(conv7)\n",
        "drop2 = tf.keras.layers.GlobalMaxPooling1D()(conv8)\n",
        "convs.append(drop2)\n",
        "\n",
        "conv9 = tf.keras.layers.Conv1D(kernel_size=6, filters=32, strides=1)(embeddings)\n",
        "conv10 = tf.keras.layers.Conv1D(kernel_size=5, filters=32, strides=1)(conv9)\n",
        "conv11 = tf.keras.layers.Conv1D(kernel_size=4, filters=32, strides=1)(conv10)\n",
        "conv12 = tf.keras.layers.Conv1D(kernel_size=3, filters=16, strides=1)(conv11)\n",
        "drop3 = tf.keras.layers.GlobalMaxPooling1D()(conv12)\n",
        "convs.append(drop3)\n",
        "\n",
        "\n",
        "concat = tf.keras.layers.concatenate(convs)\n",
        "\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(concat)\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6WEK8wSzZvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "6136bafc-2a37-4144-af99-68d5ce2ee87e"
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "         epochs=5,\n",
        "          callbacks = [checkpoint, early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "107/107 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.9208 \n",
            "Epoch 00001: val_accuracy improved from -inf to 0.93827, saving model to model.weights\n",
            "107/107 [==============================] - 5233s 49s/step - loss: 0.2448 - accuracy: 0.9208 - val_loss: 0.1675 - val_accuracy: 0.9383\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9444 \n",
            "Epoch 00002: val_accuracy improved from 0.93827 to 0.94847, saving model to model.weights\n",
            "107/107 [==============================] - 5223s 49s/step - loss: 0.1478 - accuracy: 0.9444 - val_loss: 0.1384 - val_accuracy: 0.9485\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.9509 \n",
            "Epoch 00003: val_accuracy improved from 0.94847 to 0.95062, saving model to model.weights\n",
            "107/107 [==============================] - 5316s 50s/step - loss: 0.1279 - accuracy: 0.9509 - val_loss: 0.1318 - val_accuracy: 0.9506\n",
            "Epoch 4/5\n",
            " 62/107 [================>.............] - ETA: 36:05 - loss: 0.1137 - accuracy: 0.9559"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZeuBzyGZpgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=800,\n",
        "         epochs=5,\n",
        "          callbacks = [checkpoint, early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLz9VAx2zcY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "1637599f-e9de-4c77-90b7-9ab942aaf60d"
      },
      "source": [
        "print(model.history.history.keys())\n",
        "plt.plot(model.history.history['accuracy'])\n",
        "plt.plot(model.history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9bd16c6f7a9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}